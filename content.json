{"meta":{"title":"People and Technology","subtitle":"피플앤드테크놀러지 기술 블로그 / Tech Blog","description":null,"author":"People and Technology","url":"http://yoursite.com","root":"/"},"pages":[{"title":"People and Technology","date":"2019-10-08T07:17:30.000Z","updated":"2019-10-09T03:35:37.000Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"피플앤드테크놀러지 피플앤드테크놀러지는 창립 이후로 Industrial IoT, Healthcare IoT, Building IoT 분야에서 국내외 총 30개가 넘는 고객을 확보하고 있는 국내 최고, World Class Level의 IoT Solution의 Leader 입니다. 피플앤드테크놀러지는 Bluetooth Low Energy 기반의 위치 측위 정밀도 1~2m 내외의 핵심기술을 활용하여 2014년 IndoorPlus+ LBS 및 IndoorPlus+ RTLS 제품 출시 이후 “LG 디스플레이 파주공장”, “한화 테크윈 방산공장”, “현대자동차 데이터센터”, ”아모레퍼시픽”, ”강북삼성병원” 등 산업용 IoT 및 Smart Factory의 사람 및 사물의 실시간 위치 추적 및. 모니터링 솔루션을 공급하여 작업자 안전관리(Workers Safety), 출입통제 보안(Security), 자산 관리(Asset Tracking), 공정 효율화 (Productivity) 등 Industry 4.0의 실제 적용 사례 창출을 주도하고 있습니다. 피플앤드테크놀러지는 세브란스 병원, 한양대병원, 부산대병원, 경북대병원, 호텔신라 면세점 등 Smart Phone 기반 Turn by Turn Indoor Presence 및 Navigation 시장의 No.1 Leading Provider로서 총 30개의 국내 각 비즈니스 분야의 주요 기업 및 기관에 솔루션을 공급 하였으며, 해외시장에도 진출하여 2개의 해외 레퍼런스를 확보하고 있습니다. 두 가지 유형의 솔루션을 동시에 제공하는 유일한 회사입니다 IndoorPlus+ 솔루션은 고정된 장소에 Bluetooth Beacon을 부착하여 주로 Smart Phone을 통해서 서비스를 제공하는 IndoorPlus+ LBS 솔루션과 움직이는 사람 및 Object에 Bluetooth Sensor Tag를 부착하고 Bluetooth Scanner &amp; Gateway를 통해 수집된 Signal 정보를 이용하여 서비스를 제공하는 IndoorPlus+ RTLS 등 총 2가지 솔루션을 제공합니다."}],"posts":[{"title":"Network Engine 2부","slug":"network2","date":"2019-10-12T13:47:01.000Z","updated":"2019-10-13T01:49:56.000Z","comments":true,"path":"2019/10/12/network2/","link":"","permalink":"http://yoursite.com/2019/10/12/network2/","excerpt":"","text":"IoT 에서의 네트워크 엔진3. IoT 에서의 데이터 수집시 문제점3.1. 대량의 데이터 현재 IoT 디바이스 수는 보통 우리가 생각하는 수준을 휠씬 뛰어넘고 있다. 디바이스수는 데이터량과 정비례한다. 의미있는 데이터든, 단순한 로그성 데이터든 디바이스에서 중앙저장소(서버)로 데이터를 전송하는 액션은 IoT디바이스가 가지고 있는 가장 기본적인 성향이자, 비즈니스를 하는 입장에서 추구하는 지향점이라고 할수 있다. 보통 웹브라우저에서 웹사이트에 접속하면 서버에서 로컬 클라이언트로 데이터가 전송되어 화면에 나타나게 된다. IoT디바이스의 경우 데이터의 방향이 보통의 웹사이트와 반대 방향이기 때문에 중앙저장소(서버)의 역할은 매우 크다고 할수 있다. 대량의 데이터를 서버에 처리하는 프로세스는 일반 웹서비스를 개발하는 과정과는 근본적으로 차이가 있다. 컴퓨팅 리소스는 기본이며, 애플리케이션의 견고성, 퍼포먼스는 늘 고민할 수 밖에 없다. 3.2. 초고속 데이터 일반적으로 데이터의 양이 문제가 되지만, 그와 함께 데이터 전송 주기는 데이터의 양만큼 기본적으로 고민할 수 밖에 없는 문제점이다. 주기 또는 속도는 같은 데이터의 양이라고 하더라도 서버의 리소스와 애플리케이션의 성능을 좌지우지하는 중요한 팩터(factor)이다. 규칙적으로 빠르게, 규칙적으로 느리게, 불규칙적으로 빠르게, 불규칙적으로 느리게, 이렇게 다양한 방식으로 데이터는 전송된다. 그중 가장 큰 위험요소는 불규칙적으로 빠르게 전송되는 데이터이다. 불규칙적이고 빠른 주먹은 방어하기가 쉽지 않듯이, 사전 준비나 예측이 불가능한 경우는 컴퓨팅 리소스와 애플리케이션의 성능 측면에 있어서는 치명적인 독과 같다. 3.3. 네트워크 레이턴시 인터넷 속도는 근 20년 사이에 엄청나게 빨라졌다. 스마트폰에서도 실시간으로 동영상이나 MMORPG 게임이 가능한 수준이기에 일반적으로 사용하는 유선인터넷의 속도는 가히 짐작할 수 있다. 특히 기업의 경우는 가정에서 사용하는 네트워크의 전송속도나 대역폭(bandwidth)보다 수십배는 좋기 때문에 데이터 전송에 매우 최적화되어 있다. 그렇다고 해서 모든 기업의 네트워크의 성능이 최대치라고 생각하는것은 무리가 있다. 비용문제와 보안문제 등 여러가지 이유로 전송속도와 대역폭, 그리고 특정 기간동안의 제한된 전송량은 IoT디바이스의 데이터 전송 측면에서 보면 치명적인 문제점으로 다가온다. 또한, 인위적인 제한이 아니라고 하더라도, 너무 많은 디바이스로 인해 네트워크 전송속도가 느려지고, 레이턴시(지연시간)이 늘어나게 되는 경우는 매우 자주 발생하는 현상으로 볼수 있다. 단편적으로 사무실에서 누군가 대량의 데이터를 다운로드 받거나, 업로드할때 사무실 전체 네트워크가 느려지는것이 이러한 경우라 할수 있다. 3.4. 데이터 수집 서버 성능 데이터는 중앙저장소 즉 콜렉터(collector)라고 불리우는 서버로 전송된다. 웹서비스와 다른 대량의 데이터를 초고속으로 받아서 로직을 실행하거나, 분석하거나, 또는 단순히 저장을 하는 일련의 과정은 하드웨어 서버가 아닌 서버에 설치되어 있는 애플리케이션(웹서버, 데이터 처리 애플리케이션 등등)가 수행하게 된다. 서버를 아무리 하이엔드로 구축하였다 하더라도 데이터를 처리하는 애플리케이션의 성능은 얼마나 적절한 애플리케이션을 구축했는지, 또는 적절한 아키텍처로 구성되었는지에 따라 많은 차이를 보인다. 4. IoT 에서의 데이터 수집에 새로운 접근법4.1. 새로운 아키텍처에 대한 고민 데이터 수집시 네트워크 속도나 대역폭, 그리고 전송량은 데이터를 수집해야 하는 해당 지역 또는 회사의 네트워크 인프라에 의존(Dependency)할수 밖에 없다. 기본적으로 네트워크에 문제가 발생하거나, 전송이 불규칙하거나, 데이터가 한꺼번에 몰리는 경우가 있다는 전제을 깔고, 아키텍처를 구성해야 한다. 일반적인 아키텍처는 수집 서버(또는 웹서버) 한대로 모두 처리하는 경우로 데이터베이스 역시 함께 구성한다. 또는 데이터베이스를 분리하는 경우가 그 다음으로 구성하는 단계이다. 데이터 처리가 서버 한대로 불가능한 수준까지 오게 되면, 1차적으로 스케일업(scale-up)을 하게 된다. 즉 CPU, 메모리, 스토리지 용량을 높이는 단계이다. 정통적인 서버의 경우는 스케일업조차 쉽지 않았다. 왜냐하면 직접 하드웨어를 열어서 업그레이드를 해야 했기 때문이다. 클라우드가 보편화된 요즘은 한번의 설정 변경으로 스케일업이 이루어지기 때문에 크게 문제가 되지 않는다. 만약, 스케일업 수준을 넘게되면 2차로 횡적으로 확장하는 스케일아웃(scale-out)을 시도하게 된다. 하지만, 이 마저도 어느 시점에 가게 되면 한계에 도달하게 된다. 즉, 새로운 애플리케이션, 새로운 아키텍처에 대한 고민이 시작되며, 기존의 정통적인 방식의 단순한 아키텍처로는 해결이 어렵다는것을 알게 된다. 빅데이터 아키텍처가 발전함에 따라 대용량 데이터 처리를 위한 새로운 애플리케이션, 예를 들어 스톰, 하둡, 카프카 등등 매우 다양한 애플리케이션이 나타났으면, 클라우드에서 제공하는 매니지먼트 서비스 (AWS 키네시스 등등)도 함께 발전하게 되었다. 4.2. 클라우드 컴퓨팅과 엣지 컴퓨팅 클라우드 컴퓨팅이 보편화된것이 그리 오래 되지 않았다. 기존에는 서비스를 오픈하기 위해서는 하드웨어 스펙과 대수를 산정하고 견적을 받는 업무가 필수적이였다. 인프라 지식이 없는 엔지니어나 개발자의 경우는 하드웨어 스펙을 산정하는 일이 그리 쉬운일만은 아니였다. 또한 규모가 있는 회사에서는 구매팀이 따로 있어서 서버 구매금액에 대한 네고라고 불리우는 네고시에이션(negotiation)을 수행했지만, 작은 회사, 보통 스타트업의 경우 개발리더 또는 CTO가 견적 및 네고까지 하는 경우가 비일비재했다. 특히 서버 수량의 산정은 구매 금액의 할인률과도 연관이 있고, 서비스를 어느정도까지 커버할지, 어느 정도까지 확장할지에 대한 미래 계획까지도 포함을 해서 결정해야 하는 무척 어려운 일이였다. 하지만, 클라우드가 보편화되고, 저렴(솔직히 엄청 저렴하진 않다.)해진 지금 시점에서는 서버스펙 및 서버대수에 대한 고민은 시간낭비가 되어 버렸다. 그렇다고 해도, 적절할 인스턴스 타입을 선택하고, 어떻게 아키텍처를 구성하느냐에 따라서 비용이 천차만별이기 때문에 클라우드 비용절감에 대한 고민은 지속적으로 해야 한다. 또한 좀더 저렴함 새로운 타입의 인스턴스가 지속적으로 출시되기 때문에 클라우드의 새로운 소식도 놓치지 말고 찾아보아야 한다. 클라우드 덕에 편하게 서버를 증설할수 있지만, 서버 하나하나가 모두 비용이기 때문에 데이터를 좀더 효율적으로 수집하고 처리할수 있는 방법에 대한 고민은 계속되고 있으며, 그에 대한 대안이 엣지 컴퓨팅이라는 개념이라고 생각한다. 엣지 컴퓨팅이란 쉽게 얘기해서 IoT디바이스 자체에서 클라이언트에 제공할수 있는 데이터는 자체적으로 처리하고, 꼭 필요한 데이터만 중앙서버(클라우드)에 전송하는 개념이다. 이 개념은 필요한 데이터만 전송하기 때문에 중앙 저장소에 부담이 적을뿐만 아니라 네트워크를 효율적으로 사용할수 있고, 클라이언트 입장에서는 엣지 컴퓨팅에서 바로 데이터 처리 내용을 받아 볼수 있어, 기존보다 빠르게 응답 받을수 있다. 단순히 데이터만 전송하는 IoT디바이스의 경우는 데이터를 서버로 전송할때 불필요한 데이터를 필터링할수 있는 기능만 추가하더라고, 좀더 빠르게 데이터를 수집하고, 클라우드 컴퓨팅 리소스 또한 절약할수 있다. 5. IoT 에서의 네트워크 엔진5.1. 실시간 데이터 처리 데이터의 수집시, 대량의 데이터 또는 초속 데이터에 따라 아키텍처의 구성을 다양하게 할수 있다. 무조건 저장만하고 추후에 데이터 분석에 이용한다거나, 데이터 스트림 과정중에 필요한 데이터만 캡쳐해서 저장하고 분석한다거나 할수도 있다. 여러가지 비즈니스 니즈와 다양한 솔루션 기능에 따라 데이터 구성 방법이나 데이터 저장 방법이 달라지겠지만, 실시간(100~500ms) 데이터를 가지고, 실시간으로 데이터 분석하여 어떠한 결과를 도출하는 솔루션의 경우는 데이터 수집 및 처리에 대해서 좀더 신중하게 그리고, 깊이 고민할 필요가 있다. 데이터가 들어오는 초기 진입시부터 최종 분석이나 결과를 도출하는 과정까지 처리되는 시간이 실시간으로 클라이언트에게 응답해줘야 하는 비즈니스 니즈의 상황에서 처리 파이프라인 사이사이에 애플리케이션이 추가되면 될수록 늘어남에 따라 실시간 응답이라는 취지를 잃게 되는 문제점이 생길수 있다. 안정적인 데이터 처리가 중요한 포인트라면 적절하게 파이프라인을 구축하는 방법은 최근 많이 알려진 빅데이터 기술을 사용하면 충분 처리가 가능하다. 하지만, 대량이면서 초고속 데이터를 실시간으로 빠르게 처리하고, 빠르게 응답해 주는 일은 그리 녹녹하지 않다. 솔루션 니즈에 100% 맞는 것이 없다면, 기존에 나와 있는 빅데이터 기술이나 데이터 스트림 처리가 가능한 다양한 애플리케이션에만 집중하지 말고, 데이터 처리를 위해 개발한 애플리케이션의 아키텍처를 수정함으로써 실시간 처리에 대한 문제를 해결해야 한다. 5.2. 동기, 비동기에 대한 고려 데이터 수집, 처리 및 분석시 데이터베이스는 기본적으로 사용하는 스토리지이다. 비용이나 속도문제를 해결하기 위해 레디스나 몽고디비와 같은 오픈소스 메모리 데이터베이스를 많이 사용한다. 하지만 메모리 데이터베이스를 사용했다고 해서 실시간 데이터 처리가 잘될거라는 생각은 오산이다. 데이터를 저장하는 과정은 같은 하드웨어가 아닌 다른 하드웨어 설치된 메모리 데이터베이스의 경우 네트워크를 타고 넘어가야 하는 문제로 성능이 떨어지거나 또는 디스크 IO 로 인한 성능이 떨어지게 된다. 데이터 저장시 동기 처리인지 비동기 처리인지에 따라서 데이터를 처리하는 애플리케이션 전체 성능이 결정된다. 당연히 비동기 처리에 대한 고민을 해야 하며, 애플리케이션 또는 데이터베이스가 비동기처리를 지원하는지 확인해 봐야 한다. 비동기 처리가 안되는 경우 비동기 처리가 되도록 리팩토링하거나, 프레임워크를 바꾸거나 최악의 상황에서는 개발언어를 변경해서 재구축해야 하는것도 고려해야 한다. 비동기 처리는 동기 처리보다 몇십배 좋은 성능을 보여준다는것은 이미 검증된 상황이기 때문이다. 본 내용은 작성자 개인적인 의견입니다. 다른 의견이 있으시면, 피드백 환영합니다.작성자 : 플랫폼 개발실 실장 김완철(David Kim)","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"1. IoT","slug":"it-tech/1-iot","permalink":"http://yoursite.com/categories/it-tech/1-iot/"}],"tags":[{"name":"Network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"IoT","slug":"iot","permalink":"http://yoursite.com/tags/iot/"},{"name":"RTLS","slug":"rtls","permalink":"http://yoursite.com/tags/rtls/"},{"name":"LBS","slug":"lbs","permalink":"http://yoursite.com/tags/lbs/"},{"name":"VertX","slug":"vertx","permalink":"http://yoursite.com/tags/vertx/"},{"name":"Node.js","slug":"node-js","permalink":"http://yoursite.com/tags/node-js/"}]},{"title":"Network Engine 1부","slug":"network","date":"2019-10-12T07:15:30.000Z","updated":"2019-10-13T01:49:56.000Z","comments":true,"path":"2019/10/12/network/","link":"","permalink":"http://yoursite.com/2019/10/12/network/","excerpt":"","text":"IoT 에서의 네트워크 엔진1. 개요 인터넷이 보편화된 시점부터 지금까지 데이터 처리에 대한 관심과 이슈는 언제나 있어 왔다. 인터넷의 속도가 느렸던 과거에는 데이터량와 처리속도에 대한 이슈가 그다지 많지는 않았지만, 에러없이 데이터 처리를 하고자 하는 생각은 속도와 데이터량에 상관없이 주요 관심사였다. 5G로 가고 있는 현시점도 마찬가지로 속도와 데이터량에 대한 관심은 실시간으로 데이터를 처리하는 솔루션 특히 서비스파트에서 많이 관심을 보이고 있다. 1.1. 데이터 수집 데이터 수집이란 말은 쉽게 생각하면, 그냥 저절로 들어오는 데이터를 모으는 행위 또는 특정한 장소에 저장되어 있는 데이터를 가져와서 저장하는 개념이 포함되어 있다. 데이터 수집은 초기 인터넷 서비스부터 회원가입이라는 개념이 있는 그 시점부터 당연스럽게 생겼던 개념이다. 초고속 인터넷망이 보편화된 현재에도 데이터 수집은 지속적으로 이루어져 왔고, 특히 빠르고, 네트워크망에 부담없이 데이터를 수집할지에 대한 고민은 여전히 숙제로 남아 있다. 1.2. 데이터 가공 데이터를 수집하고, 특정 위치에 저장하고, 해당 데이터를 읽는 행위는 데이터를 수집하는 솔루션 특히 서비스업체에서는 당연한 업무이며, 비즈니스의 한 부분이라는것에는 이견이 없다. 하지만, 가공이라는 역할은 그리 쉽지 않는 업무프로세스이다. 특히 쓰레기 데이터가 들어오면 결과물도 쓰레기라는 얘기가 있듯이, 가공하는 그 시점에 어떤 데이터를 선별하고 어떤 데이터를 이쁘게 가공할지에 대한 고민은 한순간의 문제로 끝나지 않는다. 1.3. 데이터 분석 데이터가 가공이 되면, 그 다음 프로세스로 가공된 데이터를 필요한 요건에 맞게 분석하는 일이다. 데이터 분석이 반드시 인사이트(insight) 있는 리포트를 생산하는 업무라기 보다는, 리포트를 만들수 있도록 그 전단계까지 데이터 자체를 분석하는것도 이 범위에 속한다고 생각한다. 업무 범위나 프로세스에는 충분히 이견이 있을수 있다고 생각한다. 분석단계가 데이터 처리의 마지막이라고 생각하는 경우가 보편적이기 때문이다. 하지만 내가 생각하는 분석과 인사이트(insight)는 특정한 업무범위나 분석능력 그리고 특정 도메인에 정통한 사람이 있느냐 없느냐에 따른 분석과 인사이트(insight) 업무가 분리된다고 생각한다. 1.4. 데이터 인사이트(insight) 가공 및 분석된 데이터를 특정 도메인에 정통한 멤버가 우리가 보지 못한, 또는 우리가 분석하지 못한 내용을 도출하는 액션 또는 업무프로세스가 데이터 인사이트라고 생각한다. 데이터는 누구나 수집하고 가공하고 분석할수는 있으나 그것을 가지고, 미래에 대한 예측, 예견 또는 현재의 문제점을 파악하고 도출해내는 행위야 말로 데이터 인사이트라는 용어를 붙일수 있다고 생각한다. 이 프로세스 역시 여러가지 이견이 있을수 있지만, 본인이 생각하는 것이 분석과 인사이트는 엄연히 다르다고 생각한다. 2. IoT 에서의 데이터 수집2.1. 디바이스 IoT 란 Internet of Things 의 약자로 말 그대로 어떠한 물건(에셋)에 인터넷이 결합된 것을 의미한다. 최근 4차 산업이라고 불리우는 것들중 IoT 는 빠지지 않고 단골손님처럼 회자된다. 물건하나 하나를 인터넷 망이라는 또는 무선망으로 연결한다며, 그 연결 과정에서 나오는 데이터 특히 IoT 제품(상품) 이라고 보편적으로 불리고 있는 인터넷 연결이 가능한 세탁기나 공기청정기 같은 전자제품에서 특정 서버로 데이터를 전송하게 된다면, 엄청난 데이터가 수집이 가능해지게 된다. 하지만, 인터넷 연결이 불가능한 디바이스도 존재하기 때문에, 데이터 전송을 위한 보완책이 필수적으로 마련되어야 한다. 2.2. 디바이스 서버 게이트웨이(브릿지) 인터넷망으로 연결된 IoT 제품의 경우는 서버로 특정한 데이터를 전송할수 있는 기본적인 구성은 되어 있다. 하지만, 인터넷이 가능하도록 부품을 심기 힘든 디바이스 특히 비컨이나 센서와 같은 작은 사이즈의 디바이스는 데이터를 서버로 보낼수 있는 방법이 쉽지가 않다. 이런한 문제를 해결하기 위해 브릿지 또는 게이트웨이라는 디바이스를 가지고, 작은 사이즈의 센서나 비컨들의 데이터를 서버로 전송하게 된다. 참고 : 게이트웨이(브릿지) 2.3 데이터 수집 서버(클라우드) 원하는 데이터를 수집하기 위해서는 어딘가에는 저장을 해야 한다. 대부분은 데이터베이스라는 전통적인 RDB를 이용하게 된다. 인터넷이 발달하기 시작한 시점의 인터넷 서비스 또는 솔루션에서는 RDB(오라클, MSSQL, MYSQL)는 매우 유용한 없어서는 안될 신과 같은 존재였다. 요즘도 마찬가지로 반드시 있어야 하는 애플리케이션이다. 하지만, 최근들어 인터넷 속도가 빨라지고, IoT 라는 디바이스에서 수집되는 데이터 그리고, 인터넷 역사에 길어짐에 따라 엄청나게 축된 데이터들 처리하기 위해서는 전통적인 아키텍처 또는 전통적인 애플리케이션으로는 해결하기 쉽지가 않다. 한가지 예로, 어느순간 예상치 못하게 수집되는 데이터량이 폭발적으로 늘어나거나, 데이터 처리를 위한 프로세스가 길어짐에 따라 컴퓨팅 리소스가 부족하게 되는 기존에 예상하지도 않았던 것들이 나타나고 있다 이와 같은 경우는 전통적인 방식 또는 아키텍처 또는 생각으로는 해결할 수가 없다. NoSQL 또는 유연하게 확장이 가능한 아키텍처 구성 또는 데이터를 수집하고 처리할수 있는 애플리케이션(네트워크 엔진)의 성능이 엄청난 데이터를 흘려다니는 현대에는 반드시 필요한 기본 필수 요건이 되어 가고 있다. 다음글 : 2부 보기 본 내용은 작성자 개인적인 의견입니다. 다른 의견이 있으시면, 피드백 환영합니다.작성자 : 플랫폼 개발실 실장 김완철(David Kim)","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"1. IoT","slug":"it-tech/1-iot","permalink":"http://yoursite.com/categories/it-tech/1-iot/"}],"tags":[{"name":"Network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"IoT","slug":"iot","permalink":"http://yoursite.com/tags/iot/"},{"name":"RTLS","slug":"rtls","permalink":"http://yoursite.com/tags/rtls/"},{"name":"LBS","slug":"lbs","permalink":"http://yoursite.com/tags/lbs/"},{"name":"VertX","slug":"vertx","permalink":"http://yoursite.com/tags/vertx/"},{"name":"Node.js","slug":"node-js","permalink":"http://yoursite.com/tags/node-js/"}]},{"title":"깃허브 블로그 협업하기","slug":"hexo-pr","date":"2019-10-12T06:45:30.000Z","updated":"2019-10-13T01:42:28.000Z","comments":true,"path":"2019/10/12/hexo-pr/","link":"","permalink":"http://yoursite.com/2019/10/12/hexo-pr/","excerpt":"","text":"깃허브 블로그 협업하기 블로그를 멤버들이 작성하고자 할때, 깃허브라는 협업이 가능한 버전관리 시스템을 최대한 이용해야 합니다. 그럼, 개발 프로젝트와 동일한 프로세스로 블로그 작성법에 대해서 알아보도록 하겠습니다. Hexo 소스 리포지토리(https://github.com/tech-people/tech-people-source) 에서 fork 한다. fork 한 소스를 로컬로 clone 한다. 로컬에서 Hexo 작성 환경을 셋팅한다. ‘Hexo로 블로그 만들기 참고’ 글 작성후 로컬에서 테스트한다. 작성 및 테스타가 완료되면, 깃허브로 푸시하고, 원본 리포지토리 master 브랜치로 PR (Pull requests) 을 날린다. 관리자는 PR 요청을 받은 내용을 확인하고, 머지한후 블로그에 배포한다. 참고 : Pull requests 이란? 작성자 : 플랫폼 개발실","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"2. etc","slug":"it-tech/2-etc","permalink":"http://yoursite.com/categories/it-tech/2-etc/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"Pull requests","slug":"pull-requests","permalink":"http://yoursite.com/tags/pull-requests/"}]},{"title":"Hexo로 블로그 만들기","slug":"hexo","date":"2019-10-12T05:56:55.000Z","updated":"2019-10-11T07:08:37.000Z","comments":true,"path":"2019/10/12/hexo/","link":"","permalink":"http://yoursite.com/2019/10/12/hexo/","excerpt":"","text":"Hexo Hexo는 Node.js 기반 정적 사이트 생성기(Static site generator)의 일종이다. 여기서는 Hexo 와 hueman 테마를 이용하여 기업 IT 블로그를 구성해 보려고 한다. 맨 마지막에는 하나의 로컬 폴더에서 Hexo 데이터를 블로그로 배포하고, 소스를 백업하는 방법을 설명한다. 1. 설치 사전준비 node.js 설치 git 설치 깃허브에 블로그로 사용할 repository 생성 (예 : tech-people.github.io) 깃허브에 hexo 소스를 저장할 repository 생성 (예 : tech-people-source) 2. hexo 설치2.1. 설치 아래와 같이 hexo 를 설치한다. 1npm install -g hexo-cli hexo 소스를 저장하게될 github 리포지토리(tech-people-source) 를 clone 한후에 해당 위치에서 디렉토리를 생성하면 추후에 관리하기가 편한다. tech-people-source 를 clone 한후에 해당 위치에서 아래와 같이 디렉토리를 생성한후 init 을 실행한다. 12mkdir &lt;디렉토리명&gt;hexo init &lt;디렉토리명&gt; 제대로 설치되었는지 테스트해기 위해 아래와 같이 서버를 실행한다. 1hexo s (or server) 서버를 실행한 후에 웹브라우저에서 http://localhost:4000 에 접속해서 정상적으로 페이지가 나오면 설치가 완료된 것이다. 2.2. 글 작성하기 아래 명령어를 실행하면 /source/_post/ 아래에 .md 파일이 생성이 된다.1hexo new &lt;글 제목&gt; 2.3 작성한 글을 html로 만들기 아래 명령어를 실행하면 public 이라는 폴더가 생성되고, 글이 html 로 변환된다.1hexo g (or generate) 2.4 깃허브로 푸시하기 (글 배포하기) 글을 작성한 후 깃허브에 푸시해야 웹에서 블로그를 확인할수 있다. hexo에서 깃허브의 리포지토리(tech-people.github.io)로 바로 배포하려면 플러그인을 설치해야 한다. 아래의 명령어로 플러그인을 설치한다. 1npm install hexo-deployer-git --save _config.yml을 아래와 같이 수정한다. 1234deploy: type: git repo: https://github.com/tech-people/tech-people.github.io branch: master 아래의 명령어로 깃허브로 블로그를 배포(푸시)한다. 123hexo d -g orhexo deploy -generate 마지막으로 https://tech-people.github.io 에 접속하여 배포된 블로그 내용을 확인한다. 만약 수정한 내용이 반영이 안되면 아래 명령어로 기존 데이터를 삭제하고 다시 배포한다. 1hexo clean 3. Hueman 테마 설치 Hexo 설치가 마무리되었으면, Hueman 테마를 설치해 보자. 3.1. hexo init를 이용하여 만든 폴더로 이동한다.3.2. 해당 폴더에서 아래의 명령어로 hueman 테마 파일을 clone 한다. 1git clone https://github.com/ppoffice/hexo-theme-hueman.git themes/hueman 3.3. _config.yml에서 theme 부분을 landscape 에서 hueman 으로 수정한다. 1theme: hueman 3.4. themes/hueman 폴더에 있는 _config.yml.example를 _config.yml로 파일명을 변경한다.3.5. Hueman 테마의 Insight Search 검색엔진을 사용하기 위해 hexo-generator-json-content 를 설치한다. 1npm install -S hexo-generator-json-content 3.6. hexo s (or server)를 이용하여 로컬(http://localhost:4000) 테스트를 해본다. 4. 깃허브로 블로그로 배포(푸시)하기 위에 언급한것 처럼 아래의 명령어로 배포하면 된다. 실행하면 _config.yml에 명시된 리포지토리로 배포된다.123hexo d -g orhexo deploy -generate 5. Hexo 소스 깃허브에 저장 hexo d 명령어로 배포하면 public 폴더에 있는 내용만 _config.yml에 설정된 tech-people.github.io 리포지토리로 푸시되기 때문에, 원본소스 모두를 리포지토리에 올리려면 위에서 clone 한 tech-people-source 리포지토리로 소스트리 또는 git 명령어를 이용하여 푸시하면 된다. 결론적으로 하나의 폴더의 내용을 hexo d 와 git 명령어를 통해서 각기 다른 깃허브 리포지토리를 푸시한다고 생각하면 된다. 작성자 : 플랫폼 개발실 출처 https://hyunseob.github.io/2016/02/23/start-hexo/ https://taetaetae.github.io/2016/09/18/hexo_github_blog/","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"2. etc","slug":"it-tech/2-etc","permalink":"http://yoursite.com/categories/it-tech/2-etc/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"마크다운 (markdown)","slug":"markdown","date":"2019-10-09T05:27:53.000Z","updated":"2019-10-11T06:09:48.000Z","comments":true,"path":"2019/10/09/markdown/","link":"","permalink":"http://yoursite.com/2019/10/09/markdown/","excerpt":"","text":"마크다운 (markdown) github 블로그 페이지에 글을 작성하기 위해서는 먼저 마크다운의 기본적인 사용법을 익혀야 합니다. 1.마크다운이란? 마크다운 (Markdown)은 마크업 언어의 일종으로, 존 그루버(John Gruber)와 아론 스워츠(Aaron Swartz)가 만들었다. 온갖 태그로 범벅된 HTML 문서 등과 달리, 읽기도 쓰기도 쉬운 문서 양식을 지향한다. 그루버는 마크다운으로 작성한 문서를 HTML로 변환하는 펄 스크립트도 만들었다. 확장자는 .md 또는 .markdown을 쓰지만, 전자가 압도적으로 많이 쓰인다. 1.1 장점 문법이 쉽다. 관리가 쉽다. 지원 가능한 플랫폼과 프로그램이 많다. 1.2 단점 표준이 없어서 사용자마다 문법이 상이하다. 모든 HTML 마크업을 대신하지 못한다. 2.문법2.1 문단 제목123456# 제목1## 제목2### 제목3#### 제목4##### 제목5###### 제목6 또는 다음과 같이 사용할수 있다. 12341단계 제목=======2단계 제목------ 2.2 문단 문단을 나누기 위해서는 줄바꿈을 두번 하면 된다. 2.3 목록12345* 목록 하나* 목록 두울* 목록 세엣- 이렇게 써도- 된답니다. 순서가 있는 목록은 다음과 같이 쓴다. 이 때, 숫자는 반드시 맞춰 쓸 필요는 없다. 1234561. 첫째입니다.2. 둘째입니다.3. 셋째입니다.5. 넷째입니다. 다섯째 아닙니다.6. 이게 다섯째입니다.4. 이건 여섯째. 2.4 글자모양 글자를 굵게 하려면 다음과 같이 사용합니다. 1**굵게** 쓰거나 __두껍게__ 쓰거나 글자를 기울게 쓰려면 다음과 같이 사용합니다. 1*기울게* 쓰면서 _기울게_ 쓴다 2.5 인라인(inline) 코드 강조 숫자 1번 키 왼쪽에 있는 `(Grave)를 입력하면 됩니다. 2.6 블록(block) 코드 강조 코드 첫 줄과 마지막 줄에 Back quote ( ` ) 또는 물결( ~ ) 3개를 삽입합니다. 2.6 인용문 줄 첫번째마다 &gt; 를 쓰면 된다. 12&gt; 인용&gt;&gt; 인용 2.7 링크1[NAVER](https://naver.com &quot;링크 설명(title)을 작성하세요.&quot;) 2.8 그림 넣기123![깃허브][imgGithub] [imgGithub]: https://guides.github.com/images/logo@2x.png &quot;설명문구&quot; 2.9 가로줄 가로줄은 아래와 같이 사용합니다. 12345* * *********- - ------------- 작성자 : 플랫폼 개발실 출처 나무위키 https://heropy.blog/2017/09/30/markdown/ https://how-to-use.tistory.com/2","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"2. etc","slug":"it-tech/2-etc","permalink":"http://yoursite.com/categories/it-tech/2-etc/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://yoursite.com/tags/markdown/"}]},{"title":"플랫폼 개발실 - 플랫폼 엔지니어 채용","slug":"recruit","date":"2019-10-09T04:35:26.000Z","updated":"2019-10-09T10:41:18.000Z","comments":true,"path":"2019/10/09/recruit/","link":"","permalink":"http://yoursite.com/2019/10/09/recruit/","excerpt":"","text":"P&amp;T에서의 플랫폼 엔지니어란? P&amp;T는 국내 1위 실내위치기반 IoT 솔루션를 개발하는 소프트웨어 개발사로써, 데이터 분석, AI까지 단순한 솔루션이 아닌 플랫폼으로 거듭나기 위해 지속적으로 엔지니어에게 투자하고 R&amp;D를 통해 신규 비즈니스를 창출하고 있습니다. P&amp;T 플랫폼 개발실은 솔루션 개발 및 SaaS 서비스를 국내뿐만 아니라 해외(유럽, 사우디 등)에도 제공하고 있으며, 자유롭고 유연한 개발 마인드를 바탕으로, 회사의 기여뿐만 아니라 개인의 역량을 최대한 발휘하고 발전할 수 있도록 모든 지원을 아끼지 않고 있습니다 왜? 개발자가 아닌 엔지니어를 채용할까? 코더, 프로그래머, 개발자, 엔지니어 등등 다양한 명칭으로 사용되어 있는 상황에서 왜 굳이 개발자가 아닌 엔지니어라는 표현을 사용했을까요? 저희 플랫폼 개발실에서는 개발자의 역할뿐만 아니라 시스템 전체 즉 아키텍처를 볼수 있고, 다룰수 있고, 업그레이드 할수 있는 멤버들로 구성되어 있습니다. 단순히 솔루션 또는 SaaS 개발만이 아닌 클라우드를 운영하고, 애플리케이션을 모니터링하고 튜닝도 하며, 여러가지 역할에 재미를 느끼고 최선을 다할 수 있는 멤버를 찾고 있습니다 플랫폼 개발실에서는 이런 것이 있습니다 코드리뷰를 진행하고 있습니다. 2~3주 단위 릴리즈를 하고 있습니다. 개발/스테이지/QA 환경이 구분되어 있습니다. CI/CD 환경이 구축되어 있습니다. 자기 주도적으로 일할 수 있습니다. 이런 것이 없습니다. 주 1회 회의는 최대 30분을 넘기지 않습니다. 야근과 회식시 술을 강요하지 않습니다. 1. 요구기술 개발 언어 : Java or Node.js 프레임워크 : Spring Framework, Spring Boot, Spring Security, Mybatis 데이터베이스 : Mysql, Oracle, Redis 기타 : IntelliJ, Git, Jenkins, SonarQube 등 OOP 기반 개발 및 설계 개념 소프트웨어 공학 / 자료구조에 대한 기본지식 2. 자격요건 학력 : 무관 경력 : 무관 (신입도 지원 가능) 성별 : 무관 3. 공통역량 일반적인 의사소통 스킬 능동적이며 진취적인 사고 전문성 및 도전의식 새로운 기술 학습 열정이 높고 이를 공유하는데 인색하지 않은 분 4. 우대사항 AWS, Docker 사용 경험 우대 빅데이터 관련 개발 경험 우대 컴퓨터학과/소프트웨어학과/통계학과 출신 우대 5. 복지 혜택 퇴직금, 명절휴가비, 경조사비, 4대 보험 오전 10시~오후 7시 (자율 출퇴근제), 휴일 근무시 대체휴가 간식 무한 제공, 석식 제공 월별 통신비 및 교통비 지원 도서구입비 지원, Intellij 개발툴 지원 6. 채용절차 서류 전형 &gt; 1차 코딩 테스트 및 면접 &gt; 2차 임원 면접 &gt; 최종합격 신입/경력 동일하게 3개월간의 수습기간이 있습니다. 작성자 : 플랫폼 개발실","categories":[{"name":"Recruit","slug":"recruit","permalink":"http://yoursite.com/categories/recruit/"},{"name":"Platform Engineer","slug":"recruit/platform-engineer","permalink":"http://yoursite.com/categories/recruit/platform-engineer/"}],"tags":[{"name":"recruit","slug":"recruit","permalink":"http://yoursite.com/tags/recruit/"},{"name":"platform","slug":"platform","permalink":"http://yoursite.com/tags/platform/"},{"name":"engineer","slug":"engineer","permalink":"http://yoursite.com/tags/engineer/"}]}]}