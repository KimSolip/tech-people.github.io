{"meta":{"title":"People and Technology","subtitle":"피플앤드테크놀러지 기술 블로그 / Tech Blog","description":null,"author":"People and Technology","url":"http://yoursite.com","root":"/"},"pages":[{"title":"People and Technology","date":"2019-10-08T07:17:30.000Z","updated":"2019-10-09T03:35:37.000Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"피플앤드테크놀러지 피플앤드테크놀러지는 창립 이후로 Industrial IoT, Healthcare IoT, Building IoT 분야에서 국내외 총 30개가 넘는 고객을 확보하고 있는 국내 최고, World Class Level의 IoT Solution의 Leader 입니다. 피플앤드테크놀러지는 Bluetooth Low Energy 기반의 위치 측위 정밀도 1~2m 내외의 핵심기술을 활용하여 2014년 IndoorPlus+ LBS 및 IndoorPlus+ RTLS 제품 출시 이후 “LG 디스플레이 파주공장”, “한화 테크윈 방산공장”, “현대자동차 데이터센터”, ”아모레퍼시픽”, ”강북삼성병원” 등 산업용 IoT 및 Smart Factory의 사람 및 사물의 실시간 위치 추적 및. 모니터링 솔루션을 공급하여 작업자 안전관리(Workers Safety), 출입통제 보안(Security), 자산 관리(Asset Tracking), 공정 효율화 (Productivity) 등 Industry 4.0의 실제 적용 사례 창출을 주도하고 있습니다. 피플앤드테크놀러지는 세브란스 병원, 한양대병원, 부산대병원, 경북대병원, 호텔신라 면세점 등 Smart Phone 기반 Turn by Turn Indoor Presence 및 Navigation 시장의 No.1 Leading Provider로서 총 30개의 국내 각 비즈니스 분야의 주요 기업 및 기관에 솔루션을 공급 하였으며, 해외시장에도 진출하여 2개의 해외 레퍼런스를 확보하고 있습니다. 두 가지 유형의 솔루션을 동시에 제공하는 유일한 회사입니다 IndoorPlus+ 솔루션은 고정된 장소에 Bluetooth Beacon을 부착하여 주로 Smart Phone을 통해서 서비스를 제공하는 IndoorPlus+ LBS 솔루션과 움직이는 사람 및 Object에 Bluetooth Sensor Tag를 부착하고 Bluetooth Scanner &amp; Gateway를 통해 수집된 Signal 정보를 이용하여 서비스를 제공하는 IndoorPlus+ RTLS 등 총 2가지 솔루션을 제공합니다."}],"posts":[{"title":"Java Refactoring 1부","slug":"java-refactoring-01","date":"2019-12-24T05:34:05.000Z","updated":"2019-12-28T05:43:07.000Z","comments":true,"path":"2019/12/24/java-refactoring-01/","link":"","permalink":"http://yoursite.com/2019/12/24/java-refactoring-01/","excerpt":"","text":"작성자 : 플랫폼 개발실 서버개발팀 유현선 리팩토링 입문 1부리팩토링은 참신한 주장이 아니라 여러 설계자나 프로그래머의 경험을 정리한 것으로 이런 점에서 디자인 패턴과 유사합니다. 그래서 다른 개발에 관련된 문서들을 찾아보면 리팩토링과 디자인패턴, TDD(Test Driven Development, 테스트 주도 개발)를 같은 내용으로 함께 다루기도 합니다.하지만 이번 내용에서는 리팩토링의 기본적인 내용에 대해서만 다뤄보도록 하겠습니다. 리팩토링이라는것 자체가 좀 더 좋은 코드를 작성하기 위한 과정/방법의 하나인 만큼 너무나 당연한 얘기고 이미 코드를 작성하면서 따로 리팩토링이라는 이름을 붙이지 않고서도 이미 그렇게 작성하고 있는 내용들도 꽤 있었습니다. &lt;자바로 배우는 리팩토링 입문&gt; 책을 읽고 작성하였습니다. 리팩토링이란 외부에서 본 프로그램의 동작은 바꾸지 않고 프로그램의 내부 구조를 개선하는 것 기능추가나 버그 수정 등은 리팩토링이라고 할 수 없음 1. 리팩토링의 목적 버그를 발견하기 쉽게 만듬 기능을 추가하기 쉬워짐 코드 리뷰를 하기 용이함 2. 리팩토링 시 주의해야 할 점리팩토링을 진행하면서 실수 할 수 있고 놓치기 쉬운 점을 아래와 같이 정리해봤습니다. (1) 유닛테스트위에서 말했던 것처럼 리팩토링은 외부 동작이 변하지 않고 내부 구조만을 개선 시키는 것으로, 만약 리팩토링의 결과로 새로운 버그가 생기거나 동작이 기존의 명세와 달라진다면 그건 잘못된 리팩토링입니다.그래서 정말로 동작이 변하지 않고 제대로 된 리팩토링이 되었는지 확인하기 위해서는 유닛 테스트가 중요합니다. 리팩토링 과정에서 유닛테스트를 하는 방법은 간단합니다. 리팩토링 전에 테스트 리팩토링 진행 리팩토링 후에 테스트1번과 3번의 결과(외부 동작이)가 같다면 성공적으로 리팩토링을 완료한 것입니다. (2) Step by Step 여러개의 리팩토링을 동시에 진행하지 말 것 : 한번에 하나의 리팩토링만 진행 되돌리기 쉽게 하기 : 만약 리팩토링을 진행하다가 문제가 생기거나 하는 경우가 반드시 존재할 수 있으므로 이를 반드시 고려 단계마다 확인 : 작업 단계마다 제대로 수정이 되고 있는건지 확인 오래된 걸 새로운 걸로 바꿈 3. 리팩토링 카탈로그리팩토링들의 목적과 절차를 카탈로그 형식으로 정리한 것을 리팩토링 카탈로그라고 부릅니다.책에서 소개된 http://www.refactoring.com/ 라는 사이트가 있는데 많은 종류의 리팩토링들이 (영어지만) 수식과 함께 설명되어 있어 이해가 어렵지 않아 심심하실때 한번씩 들어가서 구경해보시는 것을 추천드립니다. 매직 넘버를 기호 상수로 치환코드 내 매직넘버(특정 의미를 갖는 숫자값)-흔히 우리가 말하는 ‘하드코딩’ 된 수치값-을 상징이 되는 이름을 써서 상수로 선언하여 치환시키는 방법입니다. 1. 리팩토링 카탈로그 이름 매직 넘버를 기호 상수로 치환 상황 상수를 사용함 문제 - 매직 넘버는 의미를 알기 어려움 - 매직 넘버가 여러 곳에 있으면 변경하기 어려움 해법 매직 넘버를 기호 상수로 치환함 결과 - 상수의 의미를 알기 쉬워짐 - 기호 상수의 값을 변경하면 상수를 사용하는 모든 곳이 변경됨 방법 1. 기호 상수 선언하기 &nbsp;&nbsp;&nbsp;&nbsp;(1) 기호 상수 선언 &nbsp;&nbsp;&nbsp;&nbsp;(2) 매직 넘버를 기호 상수로 치환 &nbsp;&nbsp;&nbsp;&nbsp;(3) 기호 상수에 의존하는 다른 매직 넘버를 찾아서 기호 상수를 사용한 표현식으로 변환 &nbsp;&nbsp;&nbsp;&nbsp;(4) 컴파일 2. 테스트 &nbsp;&nbsp;&nbsp;&nbsp;(1) 모든 기호 상수 치환이 끝나면 컴파일 해서 테스트 &nbsp;&nbsp;&nbsp;&nbsp;(2) 가능하다면 기호 상숫값을 변경한 후 컴파일해서 테스트 1. 예제아래는 실제 개발했던 코드를 예제에 맞게 간략화하여 수정, 가공한 내용입니다. (1) 리팩토링 전123456789101112private void doSituationOccurrenceSend(Patient patient) &#123; SituationOccurrenceDetail sod = new SituationOccurrenceDetail(); sod.setSittnClCode(\"SITUATION_CODE_09\"); sod.setReferenceNum(patient.getPatntNum()); sod.setReferenceType(\"patient\"); sod.setReferenceValue(patient.getPatntName()); sod.setTrgterNum(patient.getPatntNum()); sod.setTrgterType(\"patient\"); sod.setTrgterName(patient.getPatntName()); occurenceController.situationOccurrence(sod);&#125; 새로운 환자 정보가 등록되었을때 정보를 가공하여 ‘상황발생이력 등록’을 처리하는 method 입니다.여기서 sod.setReferenceType(&quot;patient&quot;); sod.setTrgterType(&quot;patient&quot;); 이 부분을 보면 환자(patient)라는 구분값이 일반 string 값으로 하드코딩 되어있습니다. sod.setSittnClCode(&quot;SITUATION_CODE_09&quot;); 이 부분 또한 특정한 코드값을 의미하는 string 값으로 따로 보면 그 의미를 알기 힘듭니다. (2) 리팩토링 후12345678910111213141516private static final String PATIENT_REGIST = \"SITUATION_CODE_09\";private static final String PATIENT = \"patient\";private void doSituationOccurrenceSend(Patient patient) &#123; SituationOccurrenceDetail sod = new SituationOccurrenceDetail(); sod.setSituationCode(PATIENT_REGIST); sod.setReferenceNum(patient.getPatntNum()); sod.setReferenceType(PATIENT); sod.setReferenceValue(patient.getPatntName()); sod.setTrgterNum(patient.getPatntNum()); sod.setTrgterType(PATIENT); sod.setTrgterName(patient.getPatntName()); occurenceController.situationOccurrence(sod);&#125; 2. 분류 코드를 클래스로 치환하기 : enum class 사용단순히 계산값이나 URL 같은 하드코딩 값은 상수로 선언하여 사용하면 되지만 분류코드(type code)는 enum 등을 활용하여 class로 치환하여 사용하면 좋습니다.예를 들어 내부 로직에 위해 계산된 결과에 따라 상태값을 지정해주거나 할 때 이 상태값을 enum 클래스로 생성하여 관리하면 어떤 상태값들이 있는지 확인하고 수정, 추가하기가 쉽습니다. (1) 예제 12345678910111213141516171819public enum SensorStatusType implements EnumValue&lt;String&gt; &#123; NONE(\"\"), OUTOFRANGE(\"OUTOFRANGE\"), CRITICAL(\"CRITICAL\"), WARNING(\"WARNING\"), NORMAL(\"NORMAL\"); SensorStatusType(String value) &#123; this.value = value; &#125; private String value; @Override public String getValue() &#123; return value; &#125;&#125; 센서의 상태 분류값 enum class 로 위와 같이 enum을 사용할 수 있다. 메소드 추출하나의 method 는 그 이름에 맞는 하나의 기능만 처리하는 것이 좋습니다.만약 한 메소드 안에 이러저런 세세한 처리가 많다면 그런 처리를 묶어서 나누고 독립된 메소드로 추출하는 것이 메소드 추출 리팩토링입니다.저 같은 경우는 어떤 기능을 개발 할 때 처리해야 할 내용을 순서대로 작성 처리 내용에 따라 보통 Test 코드로 하나의 method 에 기능을 전부 작성 테스트로 그 기능이 정상적으로 작동하는지 확인 정상적으로 작동하는 코드를 기능별로 method 로 분리 하는 과정을 거치는데 여기서 4번이 이번에 서술할 메소드 추출 리팩토링에 속한다고 볼 수 있을것 같습니다. 1. 리팩토링 카탈로그 이름 메소드 추출(Extract Method) 상황 메소드를 작성함 문제 메소드 하나가 너무 긺 해법 기존 메소드에서 묶을 수 있는 코드를 추출해 새로운 메소드를 작성함 결과 O 각 메소드가 짧아짐 X 메소드 개수가 늘어남 방법 1. 새로운 메소드 작성 &nbsp;&nbsp;&nbsp;&nbsp;(1) 새로운 메소드에 적절한 이름 붙이기 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 메소드가 무엇을 하는지 잘 알 수 있는 이름을 붙임 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 메소드에서 실제로 어떻게 처리하는지 뜻하는 이름은 붙이지 않음 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 적당한 이름을 붙일 수 없다면 적당한 메소드가 아님 &nbsp;&nbsp;&nbsp;&nbsp;(2) 기존 메소드에서 새로운 메소드로 코드 복사 &nbsp;&nbsp;&nbsp;&nbsp;(3) 메소드 내부의 지역 변수 검토 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 복잡한 코드 안에서만 사용하는 변수라면 메소드의 지역 변수로 만듦 &nbsp;&nbsp;&nbsp;&nbsp;(4) 메소드 매개변수 검토 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 복사한 코드에서 입력값으로 사용하는 변수가 있다면 메소드 매개변수로 만듦 &nbsp;&nbsp;&nbsp;&nbsp;(5) 메소드 반환값 검토 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 복사한 코드에서 변경되는 변수가 있는지 조사 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 변경된 변수가 여러 개 있다면 리팩토링을 계속하기 어려움 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- 변경된 변수가 하나뿐이라면 ‘메소드 반환값’으로 쓰기에 적당한지 검토 2. 새로운 메소드 호출 &nbsp;&nbsp;&nbsp;&nbsp;(1) 기존 메소드에서 앞서 코드를 복사한 부분을 새로운 메소드 호출로 치환 &nbsp;&nbsp;&nbsp;&nbsp;(2) 기존 메소드에서 더는 사용하지 않는 지역 변수가 있으면 삭제 &nbsp;&nbsp;&nbsp;&nbsp;(3) 컴파일 후 테스트 2. 예제 + IntelliJ의 Refactor &gt; Extract Method 기능IntelliJ IDEA는 리팩토링에 강력한 여러가지 기능들을 제공해주고 있습니다. 여기서 그 중 하나인 메소드 추출 기능을 예제와 함께 설명하겠습니다. (1) 리팩토링 전 아래 코드는 하루동안의 입실/퇴실 목록을 조회하는 JSON 으로 각각 가져오는 Query 는 다르지만 넘겨주는 parameter 값이 중복되고 있습니다. 12345678910111213141516171819202122232425@RequestMapping(value = \"/dashboard/inList.json\", method = RequestMethod.POST)@ResponseBodypublic Object getTodayFloorInTargetList() &#123; FloorLogSearchParam logSearchParam = new FloorLogSearchParam(); TimeZone loginTimeZone = TimeZone.getTimeZone(Security.getLoginDetail().getTimeZone()); logSearchParam.setComNum(Security.getLoginDetail().getCompanyNumber()); logSearchParam.setStartDate((int) DateUtil.str2timestamp(DateUtil.getDate(\"yyyy-MM-dd 00:00:00\"), \"yyyy-MM-dd HH:mm:ss\", loginTimeZone)); logSearchParam.setEndDate((int) DateUtil.str2timestamp(DateUtil.getDate(\"yyyy-MM-dd 23:59:59\"), \"yyyy-MM-dd HH:mm:ss\", loginTimeZone)); List&lt;?&gt; res = presenceFloorService.getTodayFloorInList(logSearchParam); return res;&#125;@RequestMapping(value = \"/dashboard/outList.json\", method = RequestMethod.POST)@ResponseBodypublic Object getTodayFloorOutTargetList() &#123; FloorLogSearchParam logSearchParam = new FloorLogSearchParam(); TimeZone loginTimeZone = TimeZone.getTimeZone(Security.getLoginDetail().getTimeZone()); logSearchParam.setComNum(Security.getLoginDetail().getCompanyNumber()); logSearchParam.setStartDate((int) DateUtil.str2timestamp(DateUtil.getDate(\"yyyy-MM-dd 00:00:00\"), \"yyyy-MM-dd HH:mm:ss\", loginTimeZone)); logSearchParam.setEndDate((int) DateUtil.str2timestamp(DateUtil.getDate(\"yyyy-MM-dd 23:59:59\"), \"yyyy-MM-dd HH:mm:ss\", loginTimeZone)); List&lt;?&gt; res = presenceFloorService.getTodayFloorOutList(logSearchParam); return res;&#125; (2) 리팩토링 후중복된 검색Parameter 설정을 method 로 분리 123456789101112131415161718192021222324@RequestMapping(value = \"/dashboard/inList.json\", method = RequestMethod.POST)@ResponseBodypublic Object getTodayFloorInTargetList() &#123; FloorLogSearchParam logSearchParam = setSearchParam(); List&lt;?&gt; res = presenceFloorService.getTodayFloorInList(logSearchParam); return res;&#125;@RequestMapping(value = \"/dashboard/outList.json\", method = RequestMethod.POST)@ResponseBodypublic Object getTodayFloorOutTargetList() &#123; FloorLogSearchParam logSearchParam = setSearchParam(); List&lt;?&gt; res = presenceFloorService.getTodayFloorOutList(logSearchParam); return res;&#125;private FloorLogSearchParam setSearchParam() &#123; FloorLogSearchParam logSearchParam = new FloorLogSearchParam(); TimeZone loginTimeZone = TimeZone.getTimeZone(Security.getLoginDetail().getTimeZone()); logSearchParam.setStartDate((int) DateUtil.str2timestamp(DateUtil.getDate(\"yyyy-MM-dd 00:00:00\"), \"yyyy-MM-dd HH:mm:ss\", loginTimeZone)); logSearchParam.setEndDate((int) DateUtil.str2timestamp(DateUtil.getDate(\"yyyy-MM-dd 23:59:59\"), \"yyyy-MM-dd HH:mm:ss\", loginTimeZone)); logSearchParam.setComNum(Security.getLoginDetail().getCompanyNumber()); return logSearchParam;&#125; (3) IntelliJ 의 Extract Method 기능 추출할 메소드를 블럭 오른쪽 마우스 클릭 &gt; Refactor &gt; Extract Method (단축키 : Ctrl + Alt + M) 자동으로 선택된 코드가 method 로 분리됨 선택했던 영역 외에도 중복으로 코드가 작성된 부분이 있다면 자동으로 생성된 메소드로 대체","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"4. Java","slug":"it-tech/4-java","permalink":"http://yoursite.com/categories/it-tech/4-java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"React[hooks]-개발환경 구축하기 1부","slug":"react-hooks-chapter01","date":"2019-12-12T05:56:55.000Z","updated":"2019-12-15T01:42:46.000Z","comments":true,"path":"2019/12/12/react-hooks-chapter01/","link":"","permalink":"http://yoursite.com/2019/12/12/react-hooks-chapter01/","excerpt":"","text":"작성자 : 플랫폼 개발실 R&amp;D팀 유주빈 들어가기 앞서 기존의 HTML , CSS를 이용하여 충분히 웹 사이트를 만들 수 있습니다. 또한 자바스크립트까지 활용한다면 동적인 요소들도 제어할 수 있습니다. 그러나 앞서 말한 HTML , CSS , 순수한 자바스크립트로만 프론트 엔드를 개발한다는 것은 상당히 복잡하고 어렵습니다. 이러한 부분을 이 글에서 설명할 React를 통해 체계적으로 프론트 엔드 개발을 할 수 있게 됩니다. React란 리액트는 페이스북에서 제공을 하고 있는 프론트 엔드 라이브러리 입니다. 이는 컴포넌트 기반으로 개발자가 UI를 설계하도록 도와줍니다. React의 특징1. 컴포넌트 기반 위에서 언급했듯이 React는 컴포넌트 기반이라고 하였습니다. 이를 설명하기 위하여 아래의 사진을 보도록 하겠습니다. 위의 사진은 이 글에서 실습할 React dom 구조 및 컴포넌트 구조입니다. 일반적인 태그로 아주 간단한 dom 트리구조를 갖고 있습니다. 그러나 빨강색 박스로 한개 이상의 dom을 묶은 컴포넌트 또한 확인할 수 있습니다. 즉, 컴포넌트는 여러개의 태그를 갖을 수 있으며 해당 태그에 대한 로직과 UI 표현을 제어할 수 있습니다. 2. virtual dom(가상 dom) React를 통해 개발을 하는 개발자는 상황에 따라 다르지만 대게 직접적인 Dom을 제어하여 UI를 수정하지 않습니다. 개발자는 컴포넌트의 상태만을 관리하며 이러한 상태를 React의 적절한 로직을 통해 변경하면 가상 돔은 업데이트가 되고 실제 돔과의 비교를 하게 됩니다. 이를 통해 변동이 생긴 부분을 아예 삭제하고 변경된 dom을 해당 부분으로 변경하게 됩니다. 3. One-way Data Flow (단방향 데이터) 위에서 설명한 리액트의 특징을 종합해보면 , dom을 컴포넌트 단위로 분리할 수 있으며 해당 컴포넌트들은 각각의 state(상태)를 갖을 수 있습니다. 이렇게 다수의 컴포넌트들은 데이터를 서로에게 전달할 수 있습니다. 다만, 이러한 데이터의 흐름은 기본적으로 부모 컴포넌트에서 자식 컴포넌트로 단방향 흐름만이 가능합니다. React의 개발환경 설정1. 경로 설정 및 관련 라이브러리 다운로드하위 설명은 node가 설치되어 있다는 전제조건하에 설명에 들어가도록 하겠습니다. 이 글은 v10.16.3 버전으로 작성되었습니다. React의 본격적인 개발에 들어가기 앞서 프로젝트 폴더와 관련 라이브러리를 다운로드 받도록 하겠습니다. 현재 저는 Window 운영체제를 사용중이기 때문에 cmd창을 이용하여 설정을 하겠습니다. 아래의 명령어를 통해 디렉토리를 생성합니다. “pntbiz_react”는 개발자가 하고자 하는 이름으로 변경하셔도 됩니다. 1mkdir pntbiz_react 방금 생성한 디렉토리로 이동하여 npm 초기화를 합니다. 명령어 init을 하면 package name 및 version 등 입력해달라는 정보가 나옵니다. 본 글에서는 전부 엔터를 입력하여 해당 값을 입력하지 않았습니다. 12cd pntbiz_reactnpm init npm을 이용하여 react 라이브러리를 다운로드 합니다. 또한 react-dom 모듈 또한 설치를 합니다. react-dom은 react 모듈을 이용해 만든 내용을 실제 UI 렌더링에 사용되는 모듈입니다. 1npm install --save react react-dom React는 프로젝트 규모가 커질수록 많은 컴포넌트들이 생기며 해당되는 파일들이 무수히 많이 생성됩니다. 게다가 관련된 자바스크립트 , css , 이미지 등까지 합친다면 양이 엄청나게 불어납니다. webpack은 이러한 수 많은 파일들의 대규모 의존성을 파악하고 브라우저가 이해할 수 있도록 번들로 묶고 컴파일하는 역할을 합니다. webpack-cli는 webpack을 사용한 프로젝트를 더욱 유연하게 사용할 수 있도록 커맨드라인으로 제어할 수 있도록 도와줍니다. webpack-dev-server는 webpack을 통해 개발 서버를 열어 개발중인 결과물을 확인할 수 있도록 도와줍니다. 1npm install -D webpack webpack-cli webpack-dev-server 위에서 언급한 webpack은 다수의 파일을 하나의 번들링으로 묶고 컴파일을 한다고 하였습니다. 여기서 말하는 컴파일이란 브라우저가 이해할 수 있는 언어로 변환되는 것을 의미합니다. 결국 프론트 엔드 개발이기 때문에 최종 결과물은 브라우저가 이해를 해야합니다. 이때 사용되는 모듈이 babel 입니다. 자세히는 자바스크립트 컴파일러이며 최신 자바스크립트 문법인 ES6, ES7 , React 등의 문법을 브라우저가 이해할 수 있도록 도와주며 이러한 환경은 preset가 들어간 모듈들이 도와줍니다. 1npm install -D @babel/core @babel/preset-env @babel/preset-react babel-loader 참고 사항 : npm install에서 D 옵션을 사용함은 개발시에만 필요한 모듈을 분리하기 위함입니다.2. 개발환경 설정해당 부분에서는 위에서 내려받은 여러 모듈을 통해 React 개발환경을 구축해보도록 하겠습니다. 아래는 생성할 디렉토리의 미리보기 구조입니다. 해당 경로와 동일하게 폴더와 파일들을 생성해주세요. 아래 구조의 오른쪽 숫자는 내용을 수정할 파일의 순서입니다.123456789101112( / : 프로젝트 root 디렉토리 혹은 package.json이 있는 경로 )/index.html (1)/index.jsx (3)/package.json/package-lock.json/webpack.config.js (2)/src └─ components └─UserList.jsx (4) └─User.jsx (5)/dist (해당 폴더와 app.js는 만들지 않아도 됩니다.) └─ app.js 1) index.html 해당 파일은 실제 서버로 접속하면 처음으로 보이게 되는 html 파일입니다. 해당 소스는 아래와 같습니다. 12345678910&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;pntbiz_react&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;root&quot;&gt;&lt;/div&gt;&lt;script src=&quot;./dist/app.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 위 내용은 크게 특별한 점은 없습니다. 일반적은 head와 body로 분리가 되어 있습니다. 약간의 특이점은 하나의 div가 id로 “root”라는 속성을 갖고 있으며 script 파일로 “./dist/app.js” 경로의 app.js 파일을 호출하고 있습니다. id 속성의 값인 “root”는 꼭 “root”일 필요는 없지만 실습과 동일하게 해주세요. 2) webpack.config.js 웹팩의 기본적인 설정은 아래와 같습니다. 참고 : React에서 jsx란 자바스크립트의 확장판 문법입니다. 확장자를 jsx나 jsx로 하나 상관은 없으나 webpack에서 확장자를 이용하여 해당 파일을 어떤 방법으로 컴파일할지 정하기 때문에 해당 글에서는 jsx라고 정하겠습니다.123456789101112131415161718192021const path = require(&apos;path&apos;);module.exports = &#123; mode: &apos;development&apos;, entry: &#123; app: &apos;./index.jsx&apos;, &#125;, module: &#123; rules: [&#123; test: /\\.jsx?$/, loader: &apos;babel-loader&apos;, options: &#123; presets: [&apos;@babel/preset-env&apos;, &apos;@babel/preset-react&apos;] &#125; &#125;], &#125;, output: &#123; path: path.join(__dirname, &apos;dist&apos;), filename: &apos;app.js&apos; &#125;,&#125;; 해당 설정에서 가장 중요한 부분은 entry와 module, output 입니다. entry : 컴파일을 시작할 파일을 명시합니다. 현재는 indexjsx 파일을 통해 컴파일이 시작되며 하나 이상의 파일을 설정할 수도 있습니다. module : entry에서 시작한 컴파일의 규칙을 정하는 부분입니다. 해당 내용에서는 jsx 확장자를 option의 presets에 명시한 설정을 babel-loader가 사용하여 컴파일 하라는 내용입니다. output : 컴파일이 완료된 산출물을 생성하는 부분입니다. 현재 dist폴더에 app.js로 생성되도록 설정을 했습니다. 해당 산출물을 index.html에서 호출합니다. 3) index.jsx12345import React from &apos;react&apos;;import ReactDOM from &apos;react-dom&apos;;import UserList from &apos;./src/components/UserList.jsx&apos;ReactDOM.render(&lt;UserList/&gt; , document.querySelector(&apos;#root&apos;)); index.jsx는 webpack.config.js에서 컴파일의 시작점으로 지정한 파일이며 react와 react-dom 모듈을 불러오고 있습니다. 또한 dom의 id로 root인 dom에 UserList라는 컴포넌트를 주입하겠다는 설정입니다. 여기서 생소한 문법이 있습니다. 바로 입니다. 해당 컴포넌트를 화면에 렌더링을 하기 위해서는 컴포넌트를 태그화하여 표현을 하면 렌더링을 하게 됩니다. 4) UserList.jsx123456789101112131415import React from &apos;react&apos;;import User from &quot;./User.jsx&quot;;export default class UserList extends React.Component&#123; render() &#123; return ( &lt;div&gt; &lt;tabe&gt; &lt;User name=&#123;&apos;김아무개&apos;&#125; age=&#123;25&#125;/&gt; &lt;User name=&#123;&apos;이아무개&apos;&#125; age=&#123;26&#125;/&gt; &lt;/tabe&gt; &lt;/div&gt; ) &#125;&#125;; 자바스크립트의 class 문법을 통해 React의 Component를 extends 키워드를 통해 상속받아 컴포넌트를 생성하게 됩니다. render는 위에서 언급한 컴포넌트를 태그화하여 표현하게 되면 호출이 되어 return으로 dom을 반환하여 렌더링을 합니다. return 내부에는 위의 import 키워드로 불러온 User 컴포넌트를 사용하고 있습니다. 게다가 User 태그의 내부에는 name과 age의 속성을 명시해주고 있으며 ‘{‘를 통해 값이 들어가 있는 것을 확인할 수 있습니다. ‘{}’를 이용하면 return으로 돌려주는 dom에 자바스크립트 문법을 작성을 할 수 있습니다. 이를 위에서 언급한 React애서 jsx를 뜻합니다. 여기서는 User에 name과 age의 속성에 데이터를 내려주는 단방향 흐름을 확인할 수 있습니다. 참고 : Javascript + XML를 뜻하는 jsx는 xml형식인 dom 내부에 자바스크립트를 사용할 수 있는 문법을 일컫습니다. 리액트는 v16.8 부터 hooks라는 문법을 지원합니다. 해당 문법은 class를 통해서가 아닌 함수와 같은 형태로 함수형 컴포넌트를 만들 수 있도록 해줍니다. 위의 코드를 hooks로 변환하면 아래와 같습니다. 12345678910111213import React from &apos;react&apos;;import User from &quot;./User.jsx&quot;;export default function UserList() &#123; return ( &lt;div&gt; &lt;tabe&gt; &lt;User name=&#123;&apos;김아무개&apos;&#125; age=&#123;25&#125;/&gt; &lt;User name=&#123;&apos;이아무개&apos;&#125; age=&#123;26&#125;/&gt; &lt;/tabe&gt; &lt;/div&gt; );&#125;; 상단에 react 모듈을 불러오며 class와 동일하게 컴포넌트를 export를 합니다. 다만 함수를 선언하여 내부에 return으로 dom을 반환하면 알아서 React의 Component를 상속받아 생성된 class와 동일한 기능을 하게 됩니다. 5) User.jsx (hooks)123456789101112131415import React from &apos;react&apos;;export default class User extends React.Component&#123; constructor(props) &#123; super(props); &#125;; render() &#123; return ( &lt;tr&gt; &lt;td&gt;&#123;this.props.name&#125;&lt;/td&gt; &lt;td&gt;&#123;this.props.age&#125;&lt;/td&gt; &lt;/tr&gt; ) &#125;&#125;; UserList.jsx에서 name과 age 속성을 전달하였습니다. 해당 전달받은 값은 props로 전달이 됩니다. 이는 this.props라는 키워드를 통해 접근할 수 있습니다. 이를 통해 render함수 내부에 값의 위치를 설정할 수 있습니다. User.jsx 컴포넌트 또한 hooks 문법으로 표현하면 아래와 같습니다. 12345678910import React from &apos;react&apos;;export default function User(&#123;name,age&#125;) &#123; return ( &lt;tr&gt; &lt;td&gt;&#123;name&#125;&lt;/td&gt; &lt;td&gt;&#123;age&#125;&lt;/td&gt; &lt;/tr&gt; );&#125;; 함수형 컴포넌트의 파라메터로 값을 받아 개발자가 원하는 dom 위치에 설정을 하면 됩니다. class를 기반한 컴포넌트가 좋은지 , 함수형 컴포넌트인 hooks가 좋은지는 개발자별로 취향이 다릅니다. 다만 개인적은 의견으로는 hooks가 코드가 더욱 간결하므로 hooks를 권장드립니다. 6) 빌드 및 실행하기 cmd 창을 열거나 혹은 개발툴을 이용하여 root 경로로 이동합니다. 이동 후 아래의 명령어를 실행합니다. 1webpack 해당 명령어를 통하면 자동으로 webpack.config.js 파일을 찾아 컴파일을 시작합니다. 컴파일이 완료가 되면 /dist/app.js가 있는 것을 확인할 수 있습니다. 해당 파일을 확인했다면 webpack 개발 서버를 통해 결과물을 확인할 수 있습니다. 아래의 명령어를 입력합니다. 1webpack-dev-server 개발 서버 명령어를 통해 서버가 열리며 기본 포트인 8080으로 서버가 개설됩니다. 이제 브라우저를 열어 localhost:8080을 입력하면 아래와 같은 결과가 브러우저에 나타납니다. 12김아무개 25이아무개 26 비록 css 및 동적인 자바스크립트로 UI를 수정하여 보기 좋은 결과물은 아니지만 기본적인 React의 셋팅 및 구조에 대해서 알아보았습니다. 소스 깃허브 주소 : https://github.com/SayRew/pntbiz_react.git","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"3. React","slug":"it-tech/3-react","permalink":"http://yoursite.com/categories/it-tech/3-react/"}],"tags":[{"name":"react","slug":"react","permalink":"http://yoursite.com/tags/react/"}]},{"title":"대시보드 설계와 데이터 시각화 1부","slug":"dashboard","date":"2019-11-28T13:56:55.000Z","updated":"2019-12-15T01:39:45.000Z","comments":true,"path":"2019/11/28/dashboard/","link":"","permalink":"http://yoursite.com/2019/11/28/dashboard/","excerpt":"","text":"작성자 : 플랫폼 개발실 R&amp;D팀 신상은 대시보드 설계화 데이터 시각화 1부 이번 주제는 실무에서 많이 사용하는 대시보드를 효과적으로 설계하는 방법과 복잡한 데이터를 친숙하게 표현할 수 있도록 시각화 하는 방법에 대해 알아보도록 하겠습니다. &lt;대시보드 설계와 데이터 시각화&gt; 라는 책을 참고 하였습니다. 1. 데이터를 시각화 해야하는 이유 대시보드를 만들기 위해서는 주어진 데이터를 활용하여 시각화 하는 작업이 필요 합니다. 데이터 시각화를 활용하면 많은 양의 데이터도 시각화 차트 하나로 요약할 수 있기 때문 입니다. 시각화 차트 유형은 매우 다양한데, 이 중 어떤 시각화 차트를 활용 하느냐에 따라 같은 데이터로도 여러가지 인사이트를 발견 할수 있습니다. 시각적 분석 에서는 데이터 시각화를 얼마나 잘 이해 하고 활용 하느냐에 따라서 도출 가능한 데이터 인사이트 범위가 달라집니다. 데이터 시각화 대시보드의 장점은 여러 차트를 한 화면에 모아서 볼 수 있는 것뿐만 아니라 많은 양의 데이터를 빠르게 탐색할 수 있는 인터랙티브 기능 요소를 포함 한다는 것입니다. 데이터 필터와 차트 간 인터랙션 기능 요소를 활요하면 데이터의 조회 기간을 변경하거나, 특정 항목을 기준으로 세부 데이터를 빠르게 확인할 수 있습니다. 2. 대시보드를 만들 때 고려해야 할 사항2.1. 목적에 적합한 시각화 차트 활용 데이터 시각화 대시보드 내 개별 시각화 차트는 데이터의 특성과 활용에 맞는 시각화 유형을 사용 합니다. 같은 데이터라도 어떤 시각화 유형을 사용하느냐에 따라 직관적으로 데이터를 찾아내는 데 정도의 차이가 발생 합니다. 시간 흐름에 따라 변화하는 데이터 값의 추이 변화를 표현하고자 한다면 선 차트가 효과적이고, 전체 중 특정 항목이 차지하는 구성 비중을 표현하고자 한다면 파이 차트를 활용하는 것이 효과적입니다. 2.2. 한 화면의 시각화 차트는 5개 이내 데이터 시각화 대시보드 화면을 구성하는 시각화 차트 수는 최대 5개 정도로 제한 합니다. 종합적인 데이터 도출을 위해 여러개의 시각화 차트를 한번에 볼 필요가 있다고 해서 무조건 많은 것이 좋다고 할 수는 없습니다. 대시보드 한 화면 내 너무 많은 시각화 차트를 구성할 경우 오히려 너무 많은 시각화 차트가 보여주는 데이터 인사이트 중 무엇이 중요한 것인지 구별하기 어려운 상황을 맞게 될 수 있습니다. 효과적인 데이터 시각화 대시보드는 단순히 차트를 나열하는 것이 아닌 얻고자 하는 핵심 데이터 인사이트 도출을 목표로 설계된 것이므로, 목표 달성을 위해 필요한 최소한의 시각화 차트와 인터랙티브 기능 요소만으로도 충분히 데이터 인사이트를 도출할 수 있습니다. 2.3. 핵심 인사이트별 개별 대시보드 제작 사용자의 모든 니즈를 충족시킬 수 있는 단 하나의 대시보드를 만들려고 하기 보다는 구별되는 각각의 니즈를 충족시킬 수 있는 여러개의 데이터 시각화 대시보드를 만드는게 효과적 입니다. 단 하나의 시각화 차트로 모든 데이터 인사이트를 도출할 수 없듯이, 데이터 시각화 대시보드 하나로 찾기 원하는 모든 데이터 인사이트를 발견할 수 없습니다. 따라서 데이터 시각화 대시보드를 보는 사람이 누구인지, 데이터 탐색의 세부 기준-인구 특성별, 지역별, 시간별 등-을 무엇으로 할 것인지 등의 기준으로 개별 데이터 시각화 대시보드를 만듭니다. 한 화면으로 만들되 각 대시보드를 탭으로 구분하여 대시보드별 이동을 쉽게 하는 것도 방법 입니다. 이 경우 개별 데이터 시각화 대시보드에서 도출할 수 있는 인사이트가 구체적이고 명확하므로 효과적으로 핵심 인사이트를 빠르게 파악할 수 있습니다. 2.4. 적색과 녹색 색각 이상(CVD): 색각 이상(色覺異常)은 시력의 이상으로 인해 색상을 정상적으로 구분하지 못하는 증상을 말한다.흔히 색맹(色盲), 또는 색약(色弱)이라고도 부른다. 우리는 흔히 좋은 것을 나타낼 때는 녹색, 나쁜 것을 나타낼때는 적색을 떠올립니다. 하지만 대시보드에서 적색과 녹색을 사용한다면 색각 이상을 겪는 사람에게 치명적인 문제가 될 수 있습니다. 색각이상(CVD, Color Vision Deficiency) 주로 유전이며 남성의 8%, 여성의 1%가 많이 겪습니다. 이를 겪는 사람의 주된 문제는 적색, 녹색, 오렌지색 모두 갈색으로 보이는 것 이므로 함께 사용하지 않아야 하며, 일반적으로 흔히 신호등 색조합은 피하는 것이 좋습니다. 데이터 시각화 실무자들은 흔히 해결책으로 파란색과 오렌지 색을 사용합니다. 녹색 대신 파란색, 적색 대신 오렌지색을 사용하면 거의 모두가 파란색과 오렌지색은 구별할 수 있으므로 꽤 효과적 입니다. 이 파랑-오렌지 팔레트는 ‘색맹 친화적’이라고 일어집니다. 하지만 사용자가 원해서 적색과 녹색을 사용 해야 하는 경우, 구별된 데이터의 대안적인 방법을 제공해야 합니다. 이를 위해서는 아이콘(좋음/나쁨)을 활용하거나, 색맹 친화적인 색으로 전환할 수 있는 체크박스나 드롭박스를 사용합니다.: 색맹을 위한 디자인 조정A. 원본 이미지 B. 색맹 교정본 C. 최적화된 디자인 3. 여러 가지 차트 대시보드에서 주로 사용하는 그래프 중에 흔히 볼수 있는 그래프는 어떤 것이 있을까요? 영역 차트, 막대 차트, 꺾은선 차트, 히스토그램 그래프, 도넛 그래프 등이 존재 합니다. 그 중에서도 파이 그래프와 도넛 그래프에 대한 문제점과 대안 그래프에 대해 알아 봅니다. 정확한 정량 비교를 제시할 때 각도나 아치, 영역, 원 크기등을 사용 하는 것은 데이터를 약화 할때 길이나 위치를 사용하는 것만큼 좋지 못합니다. 이러한 이유로 파이 차트, 도넛 차트, 버블 차트는 일반적으로 데이터 시각화에 적절한 선택이 아닙니다. 가끔 예외는 있지만, 이런 차트를 사용할 때는 아주 주의 해야 합니다. 3.1. 파이 차트의 문제점 데이터에 카테고리가 많은 경우, 고려해야 할 것은 데이터 유형 입니다. 파이 차트의 목적은 부분에서 전체로의 관계 표시 입니다. 파이 차트를 읽을 때 주된 문제는 조각을 서로 비교 하는 것인데, 파이나 도넛 차트를 너무 많은 조각으로 나누게 되면 데이터를 해석하기가 더 어려워 집니다. 3.2. 도넛 차트의 문제점 도넛 차트는 부분에서 전체로의 관계를 보여주는 파이 차트의 대안으로 사용하며, 핵심성과지표(KPI)를 나타낼 때 자주 쓰입니다. 다양한 카테고리나 기간의 결함율을 보여주는 일련의 도넛 차트인 경우, 데이터의 차이를 보기가 아주 어려운 점도 문제가 됩니다. 3.3. 대안 차트 위의 문제점을 해결하기 위한 대안 차트로는 아래와 같은 그래프들이 있습니다. 3.3.1. 롤리팝 차트 막대의 높이/길이로 데이터를 규약화하고 카테고리를 한눈에 비교 할 수 있습니다. 3.3.2. 불릿 그래프 길이/높이 혹은 위치와 색으로 데이터를 규약화해 타겟이나 성과 대역에 비교한 실제를 표시합니다. 실제 값 대비 타겟의 비교를 보여주는 가장 좋은 방법에 속합니다. 3.3.3. 확산형 막대차트 중간 지점으로부터 확산 되는 막대의 길이/높이로 데이터를 규약화해 카테고리 비교를 표시 합니다. 3.3.4. 산포도 위치로 데이터를 규약화해 2가지 변수의 관계를 표시 합니다. 크기로도 2차 비교를 할 수 있습니다. 3.3.5. 트리맵 크기와 색으로 데이터를 규약화하며 계층적 데이터나 대량의 카테고리를 비교할 때 유용 합니다. 출처 도서: &lt;대시보드 설계와 데이터 시각화&gt; 색각이상 http://newsjel.ly/archives/newsjelly-report/visualization-report/9145 https://docs.microsoft.com/ko-kr/power-bi/service-dashboards https://helpx.adobe.com/kr/photoshop/using/proofing-colors.html http://hleecaster.com/how-to-draw-a-pie-radar-chart-in-excel https://www.datarevelations.com/with-great-power-comes-great-responsibility-or-think-before-you-use-a-donut-chart.html https://datavizproject.com/data-type/lollipop-chart/ https://okviz.com/blog/introducing-bullet-chart-v2-1/ https://www.makeovermonday.co.uk/week-29/ https://newsjel.ly/archives/newsjelly-report/visualization-report/9387","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"2. Data Analysis","slug":"it-tech/2-data-analysis","permalink":"http://yoursite.com/categories/it-tech/2-data-analysis/"}],"tags":[{"name":"dashboard","slug":"dashboard","permalink":"http://yoursite.com/tags/dashboard/"},{"name":"data analysis","slug":"data-analysis","permalink":"http://yoursite.com/tags/data-analysis/"}]},{"title":"비콘(Beacon)에 대한 이해","slug":"beacon-ble","date":"2019-11-13T05:56:55.000Z","updated":"2019-11-15T06:05:39.000Z","comments":true,"path":"2019/11/13/beacon-ble/","link":"","permalink":"http://yoursite.com/2019/11/13/beacon-ble/","excerpt":"","text":"작성자 : 플랫폼 개발실 서버개발팀 팀장 김대영 1. 비콘(Beacon)이란 무엇인가 전통적인 의미에서의 비콘은 어떤 신호를 알리기 위해 주기적으로 신호를 전송하는 기기를 모두 의미한다.역사적으로 보면 비콘이 가장 널리 사용된 부분은 적의 침입을 알리는 일종의 군사 연락 수단이었다. 언덕이나 높은 곳에 설치한 불빛을 의미한다. 육지에서는 적의 습격을 미리 감지해 방어 할 수 있도록 알려주는 기능을 했고 바다에서 보면 등대의 역할로 선박의 안전 운행을 유도하는 역할로 기능을 했다.따라서 옛날의 등대나 봉화 같은 것도 전통적인 의미에서는 모두 비콘에 포함된다고 할 수 있다. 이러한 비콘의 개념은 현대에 이르러 IT기술과 만나 보다 확장되고, 일상 깊숙이 들어왔다. 비콘을 활용하면 사물과 상황인식, 콘텐츠 푸시, 실내위치 측위, 자동 체크인, 지오펜스 등 다양한 응용 서비스 제공이 가능 하다. 비콘은 본질적으로 위치를 알려주는 기준점 역할을 하며, 정보 전달을 위해서는 통신기술(음파(Ultrasonic) , LED, WiFi, 블루투스) 활용이 필요하다. 2. 비콘의 종류 신호를 전송하는 방법에 따라 사운드기반의 저주파 비콘, LED 비콘, WiFi 비콘, 블루투스 비콘 등으로 나눌 수 있다. 2.1. iBeacon 아이비콘(iBeacon)은 비콘의 전통적인 개념만 따왔을 뿐 기술적으로는 기존의 비콘과는 많이 다르다. 아이비콘의 기본 개념은 위치서비스(Location Services)를 iOS로 확장한 것이다.애플이 아이비콘에 사용한 핵심 기술은 블루투스 4.0 표준에 포함된 사양 중 하나인 블루투스 로우 에너지(BLE, Bluetooth Low Energy)다. iBeacon은 BLE 4.0의 애드버터이징 패킷(Advertising Packet)전송 표준을 활용, 이를 iOS기기에 적용한 것이다.아이비콘 장치의 비콘 신호 영역 안에 iOS 기기를 소지한 사용자가 들어오면 해당 어플리케이션에 신호(Beacon)를 보내게 된다. 예를 들어 특정 상점 근처를 지나갈 때 상점에 설치된 비콘이 할인 쿠폰을 보내주거나 박물관에서 특정 전시물 앞에 가면 관련된 내용을 iOS 기기로 보내주는 등 이러한 기술을 이용할 수 있는 영역이 매우 다양하다. 2.2. no-iBeacon iBeacon 규격을 사용하지 안는 Beacon 모델도 있다. AltBeacon : Radius Networks 사에서 오픈 한 규격으로 애플의 iBeacon 규격을 보다 유연성 있게 재 구성한 비콘 이다. UriBeacon : Google의 Physical Web 프로젝트와 연계되어 특정 URI(Universal Resouce Identifier)가 포함된 Advertising Data를 브라우저를 통해 바로 정보를 보여주는 방식이다. Placedge : 삼성이 자사의 스마트폰인 갤럭시폰에 관련 기능을 지원하면서 해당 서비스 App이 설치되어 있지 않아도 이를 바로 연결해 주도록 지원하고 쿠폰, 콘텐츠 등을 전달하는 플랫폼을 별도로 개발하지 않아도 가능하도록 서버 플랫폼을 함께 제공하고 있다. 에디스톤(Eddystone) : 2015년 구글에서 발표했으며 오픈 소스 프로젝트이다. 차이점은 에디스톤의 전송패킷은 Eddyston-UID, Eddyston-URL, Eddyston-TML(Telemetry)세가지 타입이 있다. 기존 규격을 지키면서도 유연한 구조로 iOS와 Android 모두에서 잘 동작하는 것이 목표라고 한다. 3. 비콘의 장단점3.1. 장점 Bluetooth 기반의 무선 통신이지만 페어링 하는 과정이 없습니다. (사용자의 수동적인 작업이 필요 없다.) 저전력 기술이다 BLE(Bluetooth Low Energy) 기술을 활용하여 구현하여 iOS는 물론 BLE를 장착한 모든 기기(안드로이드 포함)에서 Beacon을 이용 할 수 있다. 근거리 무선 통신인 NFC가 10m 이내의 근거리에서만 작동하는 반면, Beacon은 약5m에서 50m(최대70m) 정도의 먼 거리에서도 사용이 가능하다. 안전적 거리는 20~30m이다 장비에 접촉 없이 Beacon이 설치된 곳을 지나가기만 해도 데이터 전송이 가능하다. 3.1. 단점 Beacon 자체의 보안성 문제인 스푸핑(Spoofing)과 클로닝(Cloning)에 취약 하다. 스푸핑 : 네트워크에서 MAC 주소, IP주소, 포트 등 네트워크 통신과 관련된 정보들을 속여서 통신 흐름을 왜곡시키는 공격. 클로닝 : 원본 시스템의 복제본을 하나 이상을 생성하는 것으로, 기존에 체크인 되었던 대사물의 정보를 복제하여 그 대상물이 없어도 있는 것처럼 속여서 정보를 빼내는 방법. 비콘 확산으로 많은 채널이 점유되면 비콘 간의 전파 간섭과 충돌로 인해 신호 수신율 저하와 서비스 자체가 불가능해질 우려가 있다. 비콘이 부착된 사물 또는 소유하는 사용자의 개인정보가 노출 될 수 있다. 4. Bluetooth Low Energy(BLE) BLE는 종종 Bluetooth Smart 로도 불리며 classic Bluetooth의 경량화 버전을 목표로 블루투스 4.0의 일부로 발표되었습니다. Classic Bluetooth와 겹치는 부분이 존재하지만 BLE는 완전히 다른 표준으로 블루투스 표준화 그룹인 Bluetooth SIG에 의해서 개발되기 전까지 Nokia의 사내 프로젝트(Wibree)로 시작하였습니다.BLE를 지원하는 디바이스들은 기본적으로 Advertise(Broadcast) 과 Connection 이라는 방법으로 외부와 통신한다. 4.1. Advertise Mode(Broadcast Mode) 특정 디바이스를 지정하지 않고 주변의 모든 디바이스에게 Signal을 보낸다. 다시 말해, 주변에 디바이스가 있건 없건, 다른 디바이스가 Signal을 듣는 상태이건 아니건, 자신의 Signal을 일방적으로 보내는 것이라고 생각하면 된다. 이 때, Advertising type의 Signal을 일정 주기로 보내게 된다. Advertise 관점에서, 디바이스의 역할은 다음과 같이 구분된다. Advertiser(Broadcaster) : Non-Connectable Advertising Packet을 주기적으로 보내는 디바이스. (Beacon) Observer : Advertiser가 Advertise를 Non-Connectable Advertising Packet을 듣기 위해 주기적으로 Scanning하는 디바이스. (스마트폰 및 스캐너) Advertise 방식은 한 번에 한 개 이상의 디바이스와 통신할 수 있는 유일한 방법이다. 주로 디바이스가 자신의 존재를 알리거나 적은 양(31Bytes 이하)의 User 데이터를 보낼 때도 사용된다. 한 번에 보내야 하는 데이터 크기가 작다면, 굳이 오버헤드가 큰 Connection 과정을 거쳐서 데이터를 보내기 보다는, Advertise를 이용하는 것이 더 효율적이기 때문이다. 게다가 전송할 수 있는 데이터 크기 제한을 보완하기 위해 Scan Request, Scan Response을 이용해서 추가적인 데이터를 주고 받을 수 있다. Advertise 방식은 말 그대로 Signal을 일방적으로 뿌리는 것이기 때문에 보안에 취약하다. 4.2. Connection Mode 양방향으로 데이터를 주고받거나, Advertising Packet으로만 전달하기에는 많은 양의 데이터를 주고 받아야 하는 경우에는, Connection Mode로 통신을 한다. Advertise처럼 ‘일대다’ 방식이 아닌, ‘일대일’ 방식으로 디바이스 간에 데이터 교환이 일어난다. 디바이스간에 Channel hopping 규칙을 정해놓고 통신하기 때문에 Advertise보다 안전하다.Connection 관점에서 디바이스들의 역할은 다음과 같이 구분된다. Central (Master) : Central 디바이스는 다른 디바이스와 Connection을 맺기 위해, Connectable Advertising Signal을 주기적으로 스캔 하다가, 적절한 디바이스에 연결을 요청한다. 연결이 되고 나면, Central 디바이스는 timing을 설정하고 주기적인 데이터 교환을 주도한다. 여기서 timing이란, 두 디바이스가 매번 같은 Channel에서 데이터를 주고 받기 위해 정하는 hopping 규칙이라고 생각하면 된다. Peripheral (Slave) : Peripheral 디바이스는 다른 디바이스와 Connection을 맺기 위해, Connectable Advertising Signal을 주기적으로 보낸다. 이를 수신한 Central 디바이스가 Connection Request를 보내면, 이를 수락하여 Connection을 맺는다. Connection을 맺고 나면 Central 디바이스가 지정한 timing에 맞추어 Channel을 같이 hopping을 하면서 주기적으로 데이터를 교환한다. 5. iBeacon 스펙 Advertiser’s Data (Max 31 byte) 영역은 iBeacon prefix, UUID, Major, Minor, TX Power 로 나뉩니다. iBeacon prefix(9 byte) : 비콘의 설정이나 특성 값이 기록되는 부분입니다. iBeacon 헤더 정보라 생각하시면 됩니다. 우리가 손대지 않고 정해진 값을 사용해도 됩니다. UUID (16 byte) : 사실 iBeacon에서 가장 중요한 데이터는 UUID, Major, Minor 값입니다. 이 값을 추출한 뒤, 서버에 보내서 내가 어느 위치에 있는지, 이 비콘이 어떤 역할을 하는지, 그래서 사용자에게 어떤 정보를 보여주는 것이 좋은지 판단하게 됩니다. iBeacon 관련 공식 문서를 보면 주변에서 스캔한 UUID, Major, Minor 로 사용자의 위치를 판단하는 예시들을 언급하는데, iBeacon 장치가 위치기반 서비스의 일부임을 표시하기 위해 미리 정해둔 UUID 를 사용합니다. UUID는 꼭 표준에 지정된 값을 쓸 필요는 없으며, 서비스 개발자가 임의로 지정해서 사용해도 됩니다. Major (2 byte), Minor (2 byte) : UUID 와 함께 사용자의 위치(Major, Minor = 지역, 세부 장소)를 판별하는데 주로 사용됩니다. 하지만 사용방법이 고정된 것은 아니며, 개발자가 이 값들을 임의의 목적으로 사용할 수도 있습니다. 예를 들어, 온도와 습도 데이터를 Major, Minor 데이터로 보낼 수도 있습니다. 물론 이 경우 비콘을 스캔 하는 장치도 해당 데이터를 온도, 습도로 인식하도록 만들어야 합니다. TX Power(1 byte) : 비콘 장치가 신호를 송출할 때의 power 레벨을 여기에 적어 보내줍니다. 비콘 신호를 수신할 때 신호 세기를 알 수 있기 때문에 TX power 보다 얼마나 감소했는지를 계산하고, 대강의 거리를 짐작할 수 있습니다. 하지만 이렇게 계산된 거리는 대략적인 추정치입니다. 비콘 신호는 주변 상황이나 움직임, 장애물에 의한 변동이 심할 수 있습니다. 6. iBeacon 서비스 종류 페블(pebBLE)형 : 매장 및 상점들을 겨냥한 소형 타입, 체크인 기능만 가능. 마블(MarBLE)형 : 병원이나 공항에서 실내 네비게이션을 가능케 하는 타입, 체크인과 내비게이션 기능이 모두 탑재. 님블(nimBLE)형 : 전시 솔루션이나 박물관에서 적용할 수 있는 타입, 체크인과 내비게이션 기능이 모두 탑재. 트래블(treBLE)형 : 실외용 위치 솔루션을 위한 타입, 체크인과 내비게이션 기능이 모두 탑재. 7. iBeacon 활용방법 비콘 신호를 활용하여 기획 할 수 있는 서비스는 다양 합니다. 실제 야구장의 좌석 안내 서비스, 미술관의 작품 해설 서비스, 쿠폰이나 매장 이벤트 알림 서비스, 결제 서비스, 미아 방지 서비스, 작업자 안전관리 서비스, 출입보안, 자산관리, 창고관리, 차량관제 등에 비콘이 사용되고 있습니다. 복잡한 연결 설정이나 코드 없이도 주변 비콘 장치들을 짧을 시간 안에 스캔하고 정보를 얻을 수 있는 비콘의 특징을 연구하여 획기적인 서비스로 구현해 보시기 바랍니다. 출처-http://www.ibeacon.com/what-is-ibeacon-a-guide-to-beacons-http://www.hardcopyworld.com/ngine/aduino/index.php/archives/3202-http://www.isquery.com/wiki/lib/exe/fetch.php?media=beacon_.pdf","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"1. IoT","slug":"it-tech/1-iot","permalink":"http://yoursite.com/categories/it-tech/1-iot/"}],"tags":[{"name":"beacon","slug":"beacon","permalink":"http://yoursite.com/tags/beacon/"}]},{"title":"Network Engine 2부","slug":"network2","date":"2019-10-12T13:47:01.000Z","updated":"2019-10-13T01:51:28.000Z","comments":true,"path":"2019/10/12/network2/","link":"","permalink":"http://yoursite.com/2019/10/12/network2/","excerpt":"","text":"IoT 에서의 네트워크 엔진 작성자 : 플랫폼 개발실 실장 김완철(David Kim) 3. IoT 에서의 데이터 수집시 문제점3.1. 대량의 데이터 현재 IoT 디바이스 수는 보통 우리가 생각하는 수준을 휠씬 뛰어넘고 있다. 디바이스수는 데이터량과 정비례한다. 의미있는 데이터든, 단순한 로그성 데이터든 디바이스에서 중앙저장소(서버)로 데이터를 전송하는 액션은 IoT디바이스가 가지고 있는 가장 기본적인 성향이자, 비즈니스를 하는 입장에서 추구하는 지향점이라고 할수 있다. 보통 웹브라우저에서 웹사이트에 접속하면 서버에서 로컬 클라이언트로 데이터가 전송되어 화면에 나타나게 된다. IoT디바이스의 경우 데이터의 방향이 보통의 웹사이트와 반대 방향이기 때문에 중앙저장소(서버)의 역할은 매우 크다고 할수 있다. 대량의 데이터를 서버에 처리하는 프로세스는 일반 웹서비스를 개발하는 과정과는 근본적으로 차이가 있다. 컴퓨팅 리소스는 기본이며, 애플리케이션의 견고성, 퍼포먼스는 늘 고민할 수 밖에 없다. 3.2. 초고속 데이터 일반적으로 데이터의 양이 문제가 되지만, 그와 함께 데이터 전송 주기는 데이터의 양만큼 기본적으로 고민할 수 밖에 없는 문제점이다. 주기 또는 속도는 같은 데이터의 양이라고 하더라도 서버의 리소스와 애플리케이션의 성능을 좌지우지하는 중요한 팩터(factor)이다. 규칙적으로 빠르게, 규칙적으로 느리게, 불규칙적으로 빠르게, 불규칙적으로 느리게, 이렇게 다양한 방식으로 데이터는 전송된다. 그중 가장 큰 위험요소는 불규칙적으로 빠르게 전송되는 데이터이다. 불규칙적이고 빠른 주먹은 방어하기가 쉽지 않듯이, 사전 준비나 예측이 불가능한 경우는 컴퓨팅 리소스와 애플리케이션의 성능 측면에 있어서는 치명적인 독과 같다. 3.3. 네트워크 레이턴시 인터넷 속도는 근 20년 사이에 엄청나게 빨라졌다. 스마트폰에서도 실시간으로 동영상이나 MMORPG 게임이 가능한 수준이기에 일반적으로 사용하는 유선인터넷의 속도는 가히 짐작할 수 있다. 특히 기업의 경우는 가정에서 사용하는 네트워크의 전송속도나 대역폭(bandwidth)보다 수십배는 좋기 때문에 데이터 전송에 매우 최적화되어 있다. 그렇다고 해서 모든 기업의 네트워크의 성능이 최대치라고 생각하는것은 무리가 있다. 비용문제와 보안문제 등 여러가지 이유로 전송속도와 대역폭, 그리고 특정 기간동안의 제한된 전송량은 IoT디바이스의 데이터 전송 측면에서 보면 치명적인 문제점으로 다가온다. 또한, 인위적인 제한이 아니라고 하더라도, 너무 많은 디바이스로 인해 네트워크 전송속도가 느려지고, 레이턴시(지연시간)이 늘어나게 되는 경우는 매우 자주 발생하는 현상으로 볼수 있다. 단편적으로 사무실에서 누군가 대량의 데이터를 다운로드 받거나, 업로드할때 사무실 전체 네트워크가 느려지는것이 이러한 경우라 할수 있다. 3.4. 데이터 수집 서버 성능 데이터는 중앙저장소 즉 콜렉터(collector)라고 불리우는 서버로 전송된다. 웹서비스와 다른 대량의 데이터를 초고속으로 받아서 로직을 실행하거나, 분석하거나, 또는 단순히 저장을 하는 일련의 과정은 하드웨어 서버가 아닌 서버에 설치되어 있는 애플리케이션(웹서버, 데이터 처리 애플리케이션 등등)가 수행하게 된다. 서버를 아무리 하이엔드로 구축하였다 하더라도 데이터를 처리하는 애플리케이션의 성능은 얼마나 적절한 애플리케이션을 구축했는지, 또는 적절한 아키텍처로 구성되었는지에 따라 많은 차이를 보인다. 4. IoT 에서의 데이터 수집에 새로운 접근법4.1. 새로운 아키텍처에 대한 고민 데이터 수집시 네트워크 속도나 대역폭, 그리고 전송량은 데이터를 수집해야 하는 해당 지역 또는 회사의 네트워크 인프라에 의존(Dependency)할수 밖에 없다. 기본적으로 네트워크에 문제가 발생하거나, 전송이 불규칙하거나, 데이터가 한꺼번에 몰리는 경우가 있다는 전제을 깔고, 아키텍처를 구성해야 한다. 일반적인 아키텍처는 수집 서버(또는 웹서버) 한대로 모두 처리하는 경우로 데이터베이스 역시 함께 구성한다. 또는 데이터베이스를 분리하는 경우가 그 다음으로 구성하는 단계이다. 데이터 처리가 서버 한대로 불가능한 수준까지 오게 되면, 1차적으로 스케일업(scale-up)을 하게 된다. 즉 CPU, 메모리, 스토리지 용량을 높이는 단계이다. 정통적인 서버의 경우는 스케일업조차 쉽지 않았다. 왜냐하면 직접 하드웨어를 열어서 업그레이드를 해야 했기 때문이다. 클라우드가 보편화된 요즘은 한번의 설정 변경으로 스케일업이 이루어지기 때문에 크게 문제가 되지 않는다. 만약, 스케일업 수준을 넘게되면 2차로 횡적으로 확장하는 스케일아웃(scale-out)을 시도하게 된다. 하지만, 이 마저도 어느 시점에 가게 되면 한계에 도달하게 된다. 즉, 새로운 애플리케이션, 새로운 아키텍처에 대한 고민이 시작되며, 기존의 정통적인 방식의 단순한 아키텍처로는 해결이 어렵다는것을 알게 된다. 빅데이터 아키텍처가 발전함에 따라 대용량 데이터 처리를 위한 새로운 애플리케이션, 예를 들어 스톰, 하둡, 카프카 등등 매우 다양한 애플리케이션이 나타났으면, 클라우드에서 제공하는 매니지먼트 서비스 (AWS 키네시스 등등)도 함께 발전하게 되었다. 4.2. 클라우드 컴퓨팅과 엣지 컴퓨팅 클라우드 컴퓨팅이 보편화된것이 그리 오래 되지 않았다. 기존에는 서비스를 오픈하기 위해서는 하드웨어 스펙과 대수를 산정하고 견적을 받는 업무가 필수적이였다. 인프라 지식이 없는 엔지니어나 개발자의 경우는 하드웨어 스펙을 산정하는 일이 그리 쉬운일만은 아니였다. 또한 규모가 있는 회사에서는 구매팀이 따로 있어서 서버 구매금액에 대한 네고라고 불리우는 네고시에이션(negotiation)을 수행했지만, 작은 회사, 보통 스타트업의 경우 개발리더 또는 CTO가 견적 및 네고까지 하는 경우가 비일비재했다. 특히 서버 수량의 산정은 구매 금액의 할인률과도 연관이 있고, 서비스를 어느정도까지 커버할지, 어느 정도까지 확장할지에 대한 미래 계획까지도 포함을 해서 결정해야 하는 무척 어려운 일이였다. 하지만, 클라우드가 보편화되고, 저렴(솔직히 엄청 저렴하진 않다.)해진 지금 시점에서는 서버스펙 및 서버대수에 대한 고민은 시간낭비가 되어 버렸다. 그렇다고 해도, 적절할 인스턴스 타입을 선택하고, 어떻게 아키텍처를 구성하느냐에 따라서 비용이 천차만별이기 때문에 클라우드 비용절감에 대한 고민은 지속적으로 해야 한다. 또한 좀더 저렴함 새로운 타입의 인스턴스가 지속적으로 출시되기 때문에 클라우드의 새로운 소식도 놓치지 말고 찾아보아야 한다. 클라우드 덕에 편하게 서버를 증설할수 있지만, 서버 하나하나가 모두 비용이기 때문에 데이터를 좀더 효율적으로 수집하고 처리할수 있는 방법에 대한 고민은 계속되고 있으며, 그에 대한 대안이 엣지 컴퓨팅이라는 개념이라고 생각한다. 엣지 컴퓨팅이란 쉽게 얘기해서 IoT디바이스 자체에서 클라이언트에 제공할수 있는 데이터는 자체적으로 처리하고, 꼭 필요한 데이터만 중앙서버(클라우드)에 전송하는 개념이다. 이 개념은 필요한 데이터만 전송하기 때문에 중앙 저장소에 부담이 적을뿐만 아니라 네트워크를 효율적으로 사용할수 있고, 클라이언트 입장에서는 엣지 컴퓨팅에서 바로 데이터 처리 내용을 받아 볼수 있어, 기존보다 빠르게 응답 받을수 있다. 단순히 데이터만 전송하는 IoT디바이스의 경우는 데이터를 서버로 전송할때 불필요한 데이터를 필터링할수 있는 기능만 추가하더라고, 좀더 빠르게 데이터를 수집하고, 클라우드 컴퓨팅 리소스 또한 절약할수 있다. 5. IoT 에서의 네트워크 엔진5.1. 실시간 데이터 처리 데이터의 수집시, 대량의 데이터 또는 초속 데이터에 따라 아키텍처의 구성을 다양하게 할수 있다. 무조건 저장만하고 추후에 데이터 분석에 이용한다거나, 데이터 스트림 과정중에 필요한 데이터만 캡쳐해서 저장하고 분석한다거나 할수도 있다. 여러가지 비즈니스 니즈와 다양한 솔루션 기능에 따라 데이터 구성 방법이나 데이터 저장 방법이 달라지겠지만, 실시간(100~500ms) 데이터를 가지고, 실시간으로 데이터 분석하여 어떠한 결과를 도출하는 솔루션의 경우는 데이터 수집 및 처리에 대해서 좀더 신중하게 그리고, 깊이 고민할 필요가 있다. 데이터가 들어오는 초기 진입시부터 최종 분석이나 결과를 도출하는 과정까지 처리되는 시간이 실시간으로 클라이언트에게 응답해줘야 하는 비즈니스 니즈의 상황에서 처리 파이프라인 사이사이에 애플리케이션이 추가되면 될수록 늘어남에 따라 실시간 응답이라는 취지를 잃게 되는 문제점이 생길수 있다. 안정적인 데이터 처리가 중요한 포인트라면 적절하게 파이프라인을 구축하는 방법은 최근 많이 알려진 빅데이터 기술을 사용하면 충분 처리가 가능하다. 하지만, 대량이면서 초고속 데이터를 실시간으로 빠르게 처리하고, 빠르게 응답해 주는 일은 그리 녹녹하지 않다. 솔루션 니즈에 100% 맞는 것이 없다면, 기존에 나와 있는 빅데이터 기술이나 데이터 스트림 처리가 가능한 다양한 애플리케이션에만 집중하지 말고, 데이터 처리를 위해 개발한 애플리케이션의 아키텍처를 수정함으로써 실시간 처리에 대한 문제를 해결해야 한다. 5.2. 동기, 비동기에 대한 고려 데이터 수집, 처리 및 분석시 데이터베이스는 기본적으로 사용하는 스토리지이다. 비용이나 속도문제를 해결하기 위해 레디스나 몽고디비와 같은 오픈소스 메모리 데이터베이스를 많이 사용한다. 하지만 메모리 데이터베이스를 사용했다고 해서 실시간 데이터 처리가 잘될거라는 생각은 오산이다. 데이터를 저장하는 과정은 같은 하드웨어가 아닌 다른 하드웨어 설치된 메모리 데이터베이스의 경우 네트워크를 타고 넘어가야 하는 문제로 성능이 떨어지거나 또는 디스크 IO 로 인한 성능이 떨어지게 된다. 데이터 저장시 동기 처리인지 비동기 처리인지에 따라서 데이터를 처리하는 애플리케이션 전체 성능이 결정된다. 당연히 비동기 처리에 대한 고민을 해야 하며, 애플리케이션 또는 데이터베이스가 비동기처리를 지원하는지 확인해 봐야 한다. 비동기 처리가 안되는 경우 비동기 처리가 되도록 리팩토링하거나, 프레임워크를 바꾸거나 최악의 상황에서는 개발언어를 변경해서 재구축해야 하는것도 고려해야 한다. 비동기 처리는 동기 처리보다 몇십배 좋은 성능을 보여준다는것은 이미 검증된 상황이기 때문이다. 본 내용은 작성자 개인적인 의견입니다. 다른 의견이 있으시면, 피드백 환영합니다.","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"1. IoT","slug":"it-tech/1-iot","permalink":"http://yoursite.com/categories/it-tech/1-iot/"}],"tags":[{"name":"Network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"IoT","slug":"iot","permalink":"http://yoursite.com/tags/iot/"},{"name":"RTLS","slug":"rtls","permalink":"http://yoursite.com/tags/rtls/"},{"name":"LBS","slug":"lbs","permalink":"http://yoursite.com/tags/lbs/"},{"name":"VertX","slug":"vertx","permalink":"http://yoursite.com/tags/vertx/"},{"name":"Node.js","slug":"node-js","permalink":"http://yoursite.com/tags/node-js/"}]},{"title":"Network Engine 1부","slug":"network","date":"2019-10-12T07:15:30.000Z","updated":"2019-10-13T01:51:09.000Z","comments":true,"path":"2019/10/12/network/","link":"","permalink":"http://yoursite.com/2019/10/12/network/","excerpt":"","text":"IoT 에서의 네트워크 엔진 작성자 : 플랫폼 개발실 실장 김완철(David Kim) 1. 개요 인터넷이 보편화된 시점부터 지금까지 데이터 처리에 대한 관심과 이슈는 언제나 있어 왔다. 인터넷의 속도가 느렸던 과거에는 데이터량와 처리속도에 대한 이슈가 그다지 많지는 않았지만, 에러없이 데이터 처리를 하고자 하는 생각은 속도와 데이터량에 상관없이 주요 관심사였다. 5G로 가고 있는 현시점도 마찬가지로 속도와 데이터량에 대한 관심은 실시간으로 데이터를 처리하는 솔루션 특히 서비스파트에서 많이 관심을 보이고 있다. 1.1. 데이터 수집 데이터 수집이란 말은 쉽게 생각하면, 그냥 저절로 들어오는 데이터를 모으는 행위 또는 특정한 장소에 저장되어 있는 데이터를 가져와서 저장하는 개념이 포함되어 있다. 데이터 수집은 초기 인터넷 서비스부터 회원가입이라는 개념이 있는 그 시점부터 당연스럽게 생겼던 개념이다. 초고속 인터넷망이 보편화된 현재에도 데이터 수집은 지속적으로 이루어져 왔고, 특히 빠르고, 네트워크망에 부담없이 데이터를 수집할지에 대한 고민은 여전히 숙제로 남아 있다. 1.2. 데이터 가공 데이터를 수집하고, 특정 위치에 저장하고, 해당 데이터를 읽는 행위는 데이터를 수집하는 솔루션 특히 서비스업체에서는 당연한 업무이며, 비즈니스의 한 부분이라는것에는 이견이 없다. 하지만, 가공이라는 역할은 그리 쉽지 않는 업무프로세스이다. 특히 쓰레기 데이터가 들어오면 결과물도 쓰레기라는 얘기가 있듯이, 가공하는 그 시점에 어떤 데이터를 선별하고 어떤 데이터를 이쁘게 가공할지에 대한 고민은 한순간의 문제로 끝나지 않는다. 1.3. 데이터 분석 데이터가 가공이 되면, 그 다음 프로세스로 가공된 데이터를 필요한 요건에 맞게 분석하는 일이다. 데이터 분석이 반드시 인사이트(insight) 있는 리포트를 생산하는 업무라기 보다는, 리포트를 만들수 있도록 그 전단계까지 데이터 자체를 분석하는것도 이 범위에 속한다고 생각한다. 업무 범위나 프로세스에는 충분히 이견이 있을수 있다고 생각한다. 분석단계가 데이터 처리의 마지막이라고 생각하는 경우가 보편적이기 때문이다. 하지만 내가 생각하는 분석과 인사이트(insight)는 특정한 업무범위나 분석능력 그리고 특정 도메인에 정통한 사람이 있느냐 없느냐에 따른 분석과 인사이트(insight) 업무가 분리된다고 생각한다. 1.4. 데이터 인사이트(insight) 가공 및 분석된 데이터를 특정 도메인에 정통한 멤버가 우리가 보지 못한, 또는 우리가 분석하지 못한 내용을 도출하는 액션 또는 업무프로세스가 데이터 인사이트라고 생각한다. 데이터는 누구나 수집하고 가공하고 분석할수는 있으나 그것을 가지고, 미래에 대한 예측, 예견 또는 현재의 문제점을 파악하고 도출해내는 행위야 말로 데이터 인사이트라는 용어를 붙일수 있다고 생각한다. 이 프로세스 역시 여러가지 이견이 있을수 있지만, 본인이 생각하는 것이 분석과 인사이트는 엄연히 다르다고 생각한다. 2. IoT 에서의 데이터 수집2.1. 디바이스 IoT 란 Internet of Things 의 약자로 말 그대로 어떠한 물건(에셋)에 인터넷이 결합된 것을 의미한다. 최근 4차 산업이라고 불리우는 것들중 IoT 는 빠지지 않고 단골손님처럼 회자된다. 물건하나 하나를 인터넷 망이라는 또는 무선망으로 연결한다며, 그 연결 과정에서 나오는 데이터 특히 IoT 제품(상품) 이라고 보편적으로 불리고 있는 인터넷 연결이 가능한 세탁기나 공기청정기 같은 전자제품에서 특정 서버로 데이터를 전송하게 된다면, 엄청난 데이터가 수집이 가능해지게 된다. 하지만, 인터넷 연결이 불가능한 디바이스도 존재하기 때문에, 데이터 전송을 위한 보완책이 필수적으로 마련되어야 한다. 2.2. 디바이스 서버 게이트웨이(브릿지) 인터넷망으로 연결된 IoT 제품의 경우는 서버로 특정한 데이터를 전송할수 있는 기본적인 구성은 되어 있다. 하지만, 인터넷이 가능하도록 부품을 심기 힘든 디바이스 특히 비컨이나 센서와 같은 작은 사이즈의 디바이스는 데이터를 서버로 보낼수 있는 방법이 쉽지가 않다. 이런한 문제를 해결하기 위해 브릿지 또는 게이트웨이라는 디바이스를 가지고, 작은 사이즈의 센서나 비컨들의 데이터를 서버로 전송하게 된다. 참고 : 게이트웨이(브릿지) 2.3 데이터 수집 서버(클라우드) 원하는 데이터를 수집하기 위해서는 어딘가에는 저장을 해야 한다. 대부분은 데이터베이스라는 전통적인 RDB를 이용하게 된다. 인터넷이 발달하기 시작한 시점의 인터넷 서비스 또는 솔루션에서는 RDB(오라클, MSSQL, MYSQL)는 매우 유용한 없어서는 안될 신과 같은 존재였다. 요즘도 마찬가지로 반드시 있어야 하는 애플리케이션이다. 하지만, 최근들어 인터넷 속도가 빨라지고, IoT 라는 디바이스에서 수집되는 데이터 그리고, 인터넷 역사에 길어짐에 따라 엄청나게 축된 데이터들 처리하기 위해서는 전통적인 아키텍처 또는 전통적인 애플리케이션으로는 해결하기 쉽지가 않다. 한가지 예로, 어느순간 예상치 못하게 수집되는 데이터량이 폭발적으로 늘어나거나, 데이터 처리를 위한 프로세스가 길어짐에 따라 컴퓨팅 리소스가 부족하게 되는 기존에 예상하지도 않았던 것들이 나타나고 있다 이와 같은 경우는 전통적인 방식 또는 아키텍처 또는 생각으로는 해결할 수가 없다. NoSQL 또는 유연하게 확장이 가능한 아키텍처 구성 또는 데이터를 수집하고 처리할수 있는 애플리케이션(네트워크 엔진)의 성능이 엄청난 데이터를 흘려다니는 현대에는 반드시 필요한 기본 필수 요건이 되어 가고 있다. 다음글 : 2부 보기 본 내용은 작성자 개인적인 의견입니다. 다른 의견이 있으시면, 피드백 환영합니다.","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"1. IoT","slug":"it-tech/1-iot","permalink":"http://yoursite.com/categories/it-tech/1-iot/"}],"tags":[{"name":"Network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"IoT","slug":"iot","permalink":"http://yoursite.com/tags/iot/"},{"name":"RTLS","slug":"rtls","permalink":"http://yoursite.com/tags/rtls/"},{"name":"LBS","slug":"lbs","permalink":"http://yoursite.com/tags/lbs/"},{"name":"VertX","slug":"vertx","permalink":"http://yoursite.com/tags/vertx/"},{"name":"Node.js","slug":"node-js","permalink":"http://yoursite.com/tags/node-js/"}]},{"title":"깃허브 블로그 협업하기","slug":"hexo-pr","date":"2019-10-12T06:45:30.000Z","updated":"2019-12-15T01:38:54.000Z","comments":true,"path":"2019/10/12/hexo-pr/","link":"","permalink":"http://yoursite.com/2019/10/12/hexo-pr/","excerpt":"","text":"깃허브 블로그 협업하기 블로그를 멤버들이 작성하고자 할때, 깃허브라는 협업이 가능한 버전관리 시스템을 최대한 이용해야 합니다. 그럼, 개발 프로젝트와 동일한 프로세스로 블로그 작성법에 대해서 알아보도록 하겠습니다. Hexo 소스 리포지토리(https://github.com/tech-people/tech-people-source) 에서 fork 한다. fork 한 소스를 로컬로 clone 한다. 로컬에서 Hexo 작성 환경을 셋팅한다. ‘Hexo로 블로그 만들기 참고’ 글 작성후 로컬에서 테스트한다. 작성 및 테스타가 완료되면, 깃허브로 푸시하고, 원본 리포지토리 master 브랜치로 PR (Pull requests) 을 날린다. 관리자는 PR 요청을 받은 내용을 확인하고, 머지한후 블로그에 배포한다. 참고 : Pull requests 이란? 작성자 : 플랫폼 개발실","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"9. etc","slug":"it-tech/9-etc","permalink":"http://yoursite.com/categories/it-tech/9-etc/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"Pull requests","slug":"pull-requests","permalink":"http://yoursite.com/tags/pull-requests/"}]},{"title":"Hexo로 블로그 만들기","slug":"hexo","date":"2019-10-12T05:56:55.000Z","updated":"2019-12-15T01:38:54.000Z","comments":true,"path":"2019/10/12/hexo/","link":"","permalink":"http://yoursite.com/2019/10/12/hexo/","excerpt":"","text":"Hexo Hexo는 Node.js 기반 정적 사이트 생성기(Static site generator)의 일종이다. 여기서는 Hexo 와 hueman 테마를 이용하여 기업 IT 블로그를 구성해 보려고 한다. 맨 마지막에는 하나의 로컬 폴더에서 Hexo 데이터를 블로그로 배포하고, 소스를 백업하는 방법을 설명한다. 1. 설치 사전준비 node.js 설치 git 설치 깃허브에 블로그로 사용할 repository 생성 (예 : tech-people.github.io) 깃허브에 hexo 소스를 저장할 repository 생성 (예 : tech-people-source) 2. hexo 설치2.1. 설치 아래와 같이 hexo 를 설치한다. 1npm install -g hexo-cli hexo 소스를 저장하게될 github 리포지토리(tech-people-source) 를 clone 한후에 해당 위치에서 디렉토리를 생성하면 추후에 관리하기가 편한다. tech-people-source 를 clone 한후에 해당 위치에서 아래와 같이 디렉토리를 생성한후 init 을 실행한다. 12mkdir &lt;디렉토리명&gt;hexo init &lt;디렉토리명&gt; 제대로 설치되었는지 테스트해기 위해 아래와 같이 서버를 실행한다. 1hexo s (or server) 서버를 실행한 후에 웹브라우저에서 http://localhost:4000 에 접속해서 정상적으로 페이지가 나오면 설치가 완료된 것이다. 2.2. 글 작성하기 아래 명령어를 실행하면 /source/_post/ 아래에 .md 파일이 생성이 된다.1hexo new &lt;글 제목&gt; 2.3 작성한 글을 html로 만들기 아래 명령어를 실행하면 public 이라는 폴더가 생성되고, 글이 html 로 변환된다.1hexo g (or generate) 2.4 깃허브로 푸시하기 (글 배포하기) 글을 작성한 후 깃허브에 푸시해야 웹에서 블로그를 확인할수 있다. hexo에서 깃허브의 리포지토리(tech-people.github.io)로 바로 배포하려면 플러그인을 설치해야 한다. 아래의 명령어로 플러그인을 설치한다. 1npm install hexo-deployer-git --save _config.yml을 아래와 같이 수정한다. 1234deploy: type: git repo: https://github.com/tech-people/tech-people.github.io branch: master 아래의 명령어로 깃허브로 블로그를 배포(푸시)한다. 123hexo d -g orhexo deploy -generate 마지막으로 https://tech-people.github.io 에 접속하여 배포된 블로그 내용을 확인한다. 만약 수정한 내용이 반영이 안되면 아래 명령어로 기존 데이터를 삭제하고 다시 배포한다. 1hexo clean 3. Hueman 테마 설치 Hexo 설치가 마무리되었으면, Hueman 테마를 설치해 보자. 3.1. hexo init를 이용하여 만든 폴더로 이동한다.3.2. 해당 폴더에서 아래의 명령어로 hueman 테마 파일을 clone 한다. 1git clone https://github.com/ppoffice/hexo-theme-hueman.git themes/hueman 3.3. _config.yml에서 theme 부분을 landscape 에서 hueman 으로 수정한다. 1theme: hueman 3.4. themes/hueman 폴더에 있는 _config.yml.example를 _config.yml로 파일명을 변경한다.3.5. Hueman 테마의 Insight Search 검색엔진을 사용하기 위해 hexo-generator-json-content 를 설치한다. 1npm install -S hexo-generator-json-content 3.6. hexo s (or server)를 이용하여 로컬(http://localhost:4000) 테스트를 해본다. 4. 깃허브로 블로그로 배포(푸시)하기 위에 언급한것 처럼 아래의 명령어로 배포하면 된다. 실행하면 _config.yml에 명시된 리포지토리로 배포된다.123hexo d -g orhexo deploy -generate 5. Hexo 소스 깃허브에 저장 hexo d 명령어로 배포하면 public 폴더에 있는 내용만 _config.yml에 설정된 tech-people.github.io 리포지토리로 푸시되기 때문에, 원본소스 모두를 리포지토리에 올리려면 위에서 clone 한 tech-people-source 리포지토리로 소스트리 또는 git 명령어를 이용하여 푸시하면 된다. 결론적으로 하나의 폴더의 내용을 hexo d 와 git 명령어를 통해서 각기 다른 깃허브 리포지토리를 푸시한다고 생각하면 된다. 작성자 : 플랫폼 개발실 출처 https://hyunseob.github.io/2016/02/23/start-hexo/ https://taetaetae.github.io/2016/09/18/hexo_github_blog/","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"9. etc","slug":"it-tech/9-etc","permalink":"http://yoursite.com/categories/it-tech/9-etc/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"마크다운 (markdown)","slug":"markdown","date":"2019-10-09T05:27:53.000Z","updated":"2019-12-28T06:09:52.000Z","comments":true,"path":"2019/10/09/markdown/","link":"","permalink":"http://yoursite.com/2019/10/09/markdown/","excerpt":"","text":"마크다운 (markdown) github 블로그 페이지에 글을 작성하기 위해서는 먼저 마크다운의 기본적인 사용법을 익혀야 합니다. 1.마크다운이란? 마크다운 (Markdown)은 마크업 언어의 일종으로, 존 그루버(John Gruber)와 아론 스워츠(Aaron Swartz)가 만들었다. 온갖 태그로 범벅된 HTML 문서 등과 달리, 읽기도 쓰기도 쉬운 문서 양식을 지향한다. 그루버는 마크다운으로 작성한 문서를 HTML로 변환하는 펄 스크립트도 만들었다. 확장자는 .md 또는 .markdown을 쓰지만, 전자가 압도적으로 많이 쓰인다. 1.1 장점 문법이 쉽다. 관리가 쉽다. 지원 가능한 플랫폼과 프로그램이 많다. 1.2 단점 표준이 없어서 사용자마다 문법이 상이하다. 모든 HTML 마크업을 대신하지 못한다. 2.문법2.1 문단 제목123456# 제목1## 제목2### 제목3#### 제목4##### 제목5###### 제목6 또는 다음과 같이 사용할수 있다. 12341단계 제목=======2단계 제목------ 2.2 문단 문단을 나누기 위해서는 줄바꿈을 두번 하면 된다. 2.3 목록12345* 목록 하나* 목록 두울* 목록 세엣- 이렇게 써도- 된답니다. 순서가 있는 목록은 다음과 같이 쓴다. 이 때, 숫자는 반드시 맞춰 쓸 필요는 없다. 1234561. 첫째입니다.2. 둘째입니다.3. 셋째입니다.5. 넷째입니다. 다섯째 아닙니다.6. 이게 다섯째입니다.4. 이건 여섯째. 2.4 글자모양 글자를 굵게 하려면 다음과 같이 사용합니다. 1**굵게** 쓰거나 __두껍게__ 쓰거나 글자를 기울게 쓰려면 다음과 같이 사용합니다. 1*기울게* 쓰면서 _기울게_ 쓴다 2.5 인라인(inline) 코드 강조 숫자 1번 키 왼쪽에 있는 `(Grave)를 입력하면 됩니다. 2.6 블록(block) 코드 강조 코드 첫 줄과 마지막 줄에 Back quote ( ` ) 또는 물결( ~ ) 3개를 삽입합니다. 2.6 인용문 줄 첫번째마다 &gt; 를 쓰면 된다. 12&gt; 인용&gt;&gt; 인용 2.7 링크1[NAVER](https://naver.com &quot;링크 설명(title)을 작성하세요.&quot;) 2.8 그림 넣기123![깃허브][imgGithub] [imgGithub]: https://guides.github.com/images/logo@2x.png &quot;설명문구&quot; 2.9 가로줄 가로줄은 아래와 같이 사용합니다. 12345* * *********- - ------------- 작성자 : 플랫폼 개발실 출처 나무위키 https://heropy.blog/2017/09/30/markdown/ https://how-to-use.tistory.com/2","categories":[{"name":"IT Tech","slug":"it-tech","permalink":"http://yoursite.com/categories/it-tech/"},{"name":"9. etc","slug":"it-tech/9-etc","permalink":"http://yoursite.com/categories/it-tech/9-etc/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://yoursite.com/tags/markdown/"}]},{"title":"플랫폼 개발실 - 플랫폼 엔지니어 채용","slug":"recruit","date":"2019-10-09T04:35:26.000Z","updated":"2019-11-29T06:52:16.000Z","comments":true,"path":"2019/10/09/recruit/","link":"","permalink":"http://yoursite.com/2019/10/09/recruit/","excerpt":"","text":"P&amp;T에서의 플랫폼 엔지니어란? P&amp;T는 국내 1위 실내위치기반 IoT 솔루션를 개발하는 소프트웨어 개발사로써, 데이터 분석, AI까지 단순한 솔루션이 아닌 플랫폼으로 거듭나기 위해 지속적으로 엔지니어에게 투자하고 R&amp;D를 통해 신규 비즈니스를 창출하고 있습니다. P&amp;T 플랫폼 개발실은 솔루션 개발 및 SaaS 서비스를 국내뿐만 아니라 해외(유럽, 사우디 등)에도 제공하고 있으며, 자유롭고 유연한 개발 마인드를 바탕으로, 회사의 기여뿐만 아니라 개인의 역량을 최대한 발휘하고 발전할 수 있도록 모든 지원을 아끼지 않고 있습니다 왜? 개발자가 아닌 엔지니어를 채용할까? 코더, 프로그래머, 개발자, 엔지니어 등등 다양한 명칭으로 사용되어 있는 상황에서 왜 굳이 개발자가 아닌 엔지니어라는 표현을 사용했을까요? 저희 플랫폼 개발실에서는 개발자의 역할뿐만 아니라 시스템 전체 즉 아키텍처를 볼수 있고, 다룰수 있고, 업그레이드 할수 있는 멤버들로 구성되어 있습니다. 단순히 솔루션 또는 SaaS 개발만이 아닌 클라우드를 운영하고, 애플리케이션을 모니터링하고 튜닝도 하며, 여러가지 역할에 재미를 느끼고 최선을 다할 수 있는 멤버를 찾고 있습니다 플랫폼 개발실에서는 이런 것이 있습니다 코드리뷰를 진행하고 있습니다. 2~3주 단위 릴리즈를 하고 있습니다. 개발/스테이지/QA 환경이 구분되어 있습니다. CI/CD 환경이 구축되어 있습니다. 자기 주도적으로 일할 수 있습니다. 이런 것이 없습니다. 주 1회 회의는 최대 30분을 넘기지 않습니다. 야근과 회식시 술을 강요하지 않습니다. 1. 요구기술 개발 언어 : Java or Node.js 프레임워크 : Spring Framework, Spring Boot, Spring Security, Mybatis 데이터베이스 : Mysql, Oracle, Redis 기타 : IntelliJ, Git, Jenkins, SonarQube 등 OOP 기반 개발 및 설계 개념 소프트웨어 공학 / 자료구조에 대한 기본지식 2. 자격요건 학력 : 무관 경력 : 무관 (신입도 지원 가능) 성별 : 무관 3. 공통역량 일반적인 의사소통 스킬 능동적이며 진취적인 사고 전문성 및 도전의식 새로운 기술 학습 열정이 높고 이를 공유하는데 인색하지 않은 분 4. 우대사항 AWS, Docker 사용 경험 우대 빅데이터 관련 개발 경험 우대 컴퓨터학과/소프트웨어학과/통계학과 출신 우대 5. 복지 혜택 퇴직금, 명절휴가비, 경조사비, 4대 보험 오전 10시~오후 7시 (자율 출퇴근제), 휴일 근무시 대체휴가 간식 무한 제공, 석식 제공 월별 통신비 및 교통비 지원 도서구입비 지원, Intellij 개발툴 지원 6. 채용절차 서류 전형 &gt; 1차 코딩 테스트 및 면접 &gt; 2차 임원 면접 &gt; 최종합격 신입/경력 동일하게 3개월간의 수습기간이 있습니다. 작성자 : 플랫폼 개발실","categories":[{"name":"Recruit","slug":"recruit","permalink":"http://yoursite.com/categories/recruit/"},{"name":"Platform Engineer","slug":"recruit/platform-engineer","permalink":"http://yoursite.com/categories/recruit/platform-engineer/"}],"tags":[{"name":"recruit","slug":"recruit","permalink":"http://yoursite.com/tags/recruit/"},{"name":"platform","slug":"platform","permalink":"http://yoursite.com/tags/platform/"},{"name":"engineer","slug":"engineer","permalink":"http://yoursite.com/tags/engineer/"}]}]}